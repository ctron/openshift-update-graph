{"version":1,"nodes":[{"version":"4.18.23","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0bf2e8c1edf16de717c330b94d85f6d463c7208956b0a545cbb3fcf715e14c38","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|^4[.](17[.].*|18[.](1?[0-9]|2[0-2]))[+].*$|^4[.](17[.].*|18[.](1?[0-9]|2[0-1]))[+].*$|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|17[.](([0-9]|[1-2][0-9]|3[0-7])))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0bf2e8c1edf16de717c330b94d85f6d463c7208956b0a545cbb3fcf715e14c38","url":"https://access.redhat.com/errata/RHSA-2025:14820"}},{"version":"4.19.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:3482dbdce3a6fb2239684d217bba6fc87453eff3bdb72f5237be4beb22a2160b","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.]18[.](1[01]|[0-9])[+].*$|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:3482dbdce3a6fb2239684d217bba6fc87453eff3bdb72f5237be4beb22a2160b","url":"https://access.redhat.com/errata/RHSA-2024:11038"}},{"version":"4.20.0-ec.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:4dfd7223e883a685c7be0906b09d573ef24bdb8f7fcfb1876e198bed5352ba55","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:4dfd7223e883a685c7be0906b09d573ef24bdb8f7fcfb1876e198bed5352ba55"}},{"version":"4.20.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d1dc76522d1e235b97675b28e977cb8c452f47d39c0eb519cde02114925f91d2","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]19[.]1[67][+].*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,eus-4.20,fast-4.20,stable-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:d1dc76522d1e235b97675b28e977cb8c452f47d39c0eb519cde02114925f91d2","url":"https://access.redhat.com/errata/RHSA-2025:9562"}},{"version":"4.19.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0b44c4b526b4743e744cb989c6fc768fdfd9ac9abffc8f43a014bb90b7bf522d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0b44c4b526b4743e744cb989c6fc768fdfd9ac9abffc8f43a014bb90b7bf522d","url":"https://access.redhat.com/errata/RHBA-2025:10290"}},{"version":"4.20.0-ec.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:545fb749b1352490a35532cbfba1575fc4002910e3cf68bd011036a26d6d1d3b","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:545fb749b1352490a35532cbfba1575fc4002910e3cf68bd011036a26d6d1d3b"}},{"version":"4.18.0-ec.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:e87292db8d5790f7059d90a449feab27aaa3299ac22f05f12b9bc9609468f67d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:e87292db8d5790f7059d90a449feab27aaa3299ac22f05f12b9bc9609468f67d"}},{"version":"4.19.0-rc.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:86ef3b06739c0fbcc2bd36c85e2685d19b38f7c776601a8389759648abc8e32b","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:86ef3b06739c0fbcc2bd36c85e2685d19b38f7c776601a8389759648abc8e32b","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.24","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2db093f063ad5310fa4e5ed2d2eda4bad5215c47092b72d1cfafbcfdbf1f4dd2","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.].*|18[.](1?[0-9]|2[0-2]))[+].*$|^4[.](17[.].*|18[.](1?[0-9]|2[0-1]))[+].*$|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|17[.](([0-9]|[1-2][0-9]|3[0-7])))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2db093f063ad5310fa4e5ed2d2eda4bad5215c47092b72d1cfafbcfdbf1f4dd2","url":"https://access.redhat.com/errata/RHBA-2025:15714"}},{"version":"4.18.12","payload":"quay.io/openshift-release-dev/ocp-release@sha256:31e8978d1f7a24c3e70dcc12c93dd5e73311b78e528f73beb020ddbe3270e07d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:31e8978d1f7a24c3e70dcc12c93dd5e73311b78e528f73beb020ddbe3270e07d","url":"https://access.redhat.com/errata/RHSA-2025:4427"}},{"version":"4.18.9","payload":"quay.io/openshift-release-dev/ocp-release@sha256:720f89718effd16de7d77e5533c9608f1845295a2e00dfff543d0cf9aa09b2a0","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:720f89718effd16de7d77e5533c9608f1845295a2e00dfff543d0cf9aa09b2a0","url":"https://access.redhat.com/errata/RHSA-2025:3775"}},{"version":"4.18.0-ec.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:a3233d18821af30610bc16d4a3d0f45a5f6bcfbb50eda139b8b82b824a78559f","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:a3233d18821af30610bc16d4a3d0f45a5f6bcfbb50eda139b8b82b824a78559f"}},{"version":"4.19.11","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d28dff1fd2bbbf7e923d24da21c921c53b61089690fbbe9d4b03c847487c2b5f","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|4\\.18\\..*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d28dff1fd2bbbf7e923d24da21c921c53b61089690fbbe9d4b03c847487c2b5f","url":"https://access.redhat.com/errata/RHBA-2025:15293"}},{"version":"4.20.0-rc.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:71b3ab49573d115389214a6f9091251af6f07e14917356b86d594f7b8c90bb53","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4\\.18\\..*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:71b3ab49573d115389214a6f9091251af6f07e14917356b86d594f7b8c90bb53","url":"https://access.redhat.com/errata/RHBA-2025:9562"}},{"version":"4.18.0-ec.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d2d34aafe0adda79953dd928b946ecbda34673180ee9a80d2ee37c123a0f510c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](0.*|[1-4])|18[.]0-ec[.][0-2])[+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d2d34aafe0adda79953dd928b946ecbda34673180ee9a80d2ee37c123a0f510c"}},{"version":"4.19.6","payload":"quay.io/openshift-release-dev/ocp-release@sha256:02ec914b5380b9e4e048b830c9521e8d11f7f613d4ff3977147107770288a595","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:02ec914b5380b9e4e048b830c9521e8d11f7f613d4ff3977147107770288a595","url":"https://access.redhat.com/errata/RHSA-2025:11673"}},{"version":"4.20.0-ec.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d8988b7ff4ba0281fee6c6c1dbbdfa922b6cb862d9c20ff08ab432baea86749f","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:d8988b7ff4ba0281fee6c6c1dbbdfa922b6cb862d9c20ff08ab432baea86749f"}},{"version":"4.18.13","payload":"quay.io/openshift-release-dev/ocp-release@sha256:a93c65b0f9de1d2e29641fbeebc07178733db1cacc7bde178033d7b9183540bc","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:a93c65b0f9de1d2e29641fbeebc07178733db1cacc7bde178033d7b9183540bc","url":"https://access.redhat.com/errata/RHSA-2025:4712"}},{"version":"4.18.25","payload":"quay.io/openshift-release-dev/ocp-release@sha256:ba6f0f2eca65cd386a5109ddbbdb3bab9bb9801e32de56ef34f80e634a7787be","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.].*|18[.](1?[0-9]|2[0-2]))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:ba6f0f2eca65cd386a5109ddbbdb3bab9bb9801e32de56ef34f80e634a7787be","url":"https://access.redhat.com/errata/RHBA-2025:16732"}},{"version":"4.19.0-rc.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5d3a4b9203759cf8ae97546f35128decca063e83181c2ba4407177db252e919c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:5d3a4b9203759cf8ae97546f35128decca063e83181c2ba4407177db252e919c","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.0-ec.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8e097e389656b8b6e362c596b08f929d9271b4f841570f310b13b497a4f2b7d9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.]18[.]0-ec[.][0-2][+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8e097e389656b8b6e362c596b08f929d9271b4f841570f310b13b497a4f2b7d9"}},{"version":"4.20.0-rc.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:67f4c08fae09d7aff55552bbe72865d422397e07a3df47c90201b5d09beab004","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4\\.18\\..*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:67f4c08fae09d7aff55552bbe72865d422397e07a3df47c90201b5d09beab004","url":"https://access.redhat.com/errata/RHBA-2025:9562"}},{"version":"4.19.0-ec.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2736d8dcfc57058fb77f1c34821ccfd1d07fdb505045e77493c59f06bf70e938","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2736d8dcfc57058fb77f1c34821ccfd1d07fdb505045e77493c59f06bf70e938"}},{"version":"4.18.26","payload":"quay.io/openshift-release-dev/ocp-release@sha256:dcd5fce7701d1e568ffb1065800a4aa34c911910400209224e702b951412171d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.].*|18[.](1?[0-9]|2[0-2]))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:dcd5fce7701d1e568ffb1065800a4aa34c911910400209224e702b951412171d","url":"https://access.redhat.com/errata/RHSA-2025:17657"}},{"version":"4.18.14","payload":"quay.io/openshift-release-dev/ocp-release@sha256:78c0475ba249e03b0ed5b3d3cca619020a2996fb75efb9e7b5a2d5972fbdac7c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:78c0475ba249e03b0ed5b3d3cca619020a2996fb75efb9e7b5a2d5972fbdac7c","url":"https://access.redhat.com/errata/RHSA-2025:7863"}},{"version":"4.20.0-ec.6","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b3f8a9d88cfe19675ab0a7f7238c0d74aaa72037ac31d455132072cbb924faa5","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:b3f8a9d88cfe19675ab0a7f7238c0d74aaa72037ac31d455132072cbb924faa5"}},{"version":"4.19.12","payload":"quay.io/openshift-release-dev/ocp-release@sha256:f0ca7c0e9ede6440119f3fd90abdd87e77cf99b7e68d6c1f95ec1872c62cbb17","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|.*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|4\\.18\\..*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:f0ca7c0e9ede6440119f3fd90abdd87e77cf99b7e68d6c1f95ec1872c62cbb17","url":"https://access.redhat.com/errata/RHBA-2025:15694"}},{"version":"4.19.7","payload":"quay.io/openshift-release-dev/ocp-release@sha256:bd4cd954feebfe3a6b2847c20271e8f3ba21e99ac1e234db6ce4cf2207f8955a","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:bd4cd954feebfe3a6b2847c20271e8f3ba21e99ac1e234db6ce4cf2207f8955a","url":"https://access.redhat.com/errata/RHSA-2025:12341"}},{"version":"4.19.0-rc.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:596f4d804654419241c1894fb6d54066718f254aab58dfa8892bb26390ba3df9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:596f4d804654419241c1894fb6d54066718f254aab58dfa8892bb26390ba3df9","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.15","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0ebcecebc52a63285669ed74f0e591865b702de34c0a488cbba02dfb53d71cbe","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0ebcecebc52a63285669ed74f0e591865b702de34c0a488cbba02dfb53d71cbe","url":"https://access.redhat.com/errata/RHBA-2025:8104"}},{"version":"4.19.0-ec.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:aa3e0a3a94babd90535f8298ab274b51a9bce6045dda8c3c8cd742bc59f0e2d9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.](18[.]0-(ec[.].*|rc[.][0-3])|19[.]0-ec[.]0)|.*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:aa3e0a3a94babd90535f8298ab274b51a9bce6045dda8c3c8cd742bc59f0e2d9"}},{"version":"4.18.27","payload":"quay.io/openshift-release-dev/ocp-release@sha256:4686c8d26194f890c2a241271d41a762d4be26af0be60e9cfd0c563f61b3beab","metadata":{"io.openshift.upgrades.graph.release.channels":"candidate-4.18,fast-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:4686c8d26194f890c2a241271d41a762d4be26af0be60e9cfd0c563f61b3beab","url":"https://access.redhat.com/errata/RHSA-2025:19047"}},{"version":"4.18.0-rc.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:054e75395dd0879e8c29cd059cf6b782742123177a303910bf78f28880431d1c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.]18[.]0-ec[.][0-2][+].*$|4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:054e75395dd0879e8c29cd059cf6b782742123177a303910bf78f28880431d1c","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.17","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5c01281c55d75a1569440f91d2708125f14533c675b96d7be67b7a1badd759e5","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.].*|4\\.18\\..*|^4[.](18[.][0-9]*|19[.]([0-9]|1[0-2]))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:5c01281c55d75a1569440f91d2708125f14533c675b96d7be67b7a1badd759e5","url":"https://access.redhat.com/errata/RHSA-2025:18233"}},{"version":"4.18.0-rc.10","payload":"quay.io/openshift-release-dev/ocp-release@sha256:35f285f833999f8d91300428c7401eae71759901cc821c33e0a7312d5e6444d7","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:35f285f833999f8d91300428c7401eae71759901cc821c33e0a7312d5e6444d7","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.16","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0dac222584991f89a123d85e8c3055f0056e5876fc209b8d4bea7a59e7504d59","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0dac222584991f89a123d85e8c3055f0056e5876fc209b8d4bea7a59e7504d59","url":"https://access.redhat.com/errata/RHSA-2025:8284"}},{"version":"4.19.18","payload":"quay.io/openshift-release-dev/ocp-release@sha256:3fb2c0faf6cc35dae23fd9fb4182c89df3e7c5272505652c7e6dced31c416daf","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.].*|4\\.18\\..*|^4[.](18[.][0-9]*|19[.]([0-9]|1[0-2]))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:3fb2c0faf6cc35dae23fd9fb4182c89df3e7c5272505652c7e6dced31c416daf","url":"https://access.redhat.com/errata/RHBA-2025:19301"}},{"version":"4.18.17","payload":"quay.io/openshift-release-dev/ocp-release@sha256:9d24a8cdd67b8f18c99547d5910e4863e7aab5bd888e26670a00dbda0a9d4687","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:9d24a8cdd67b8f18c99547d5910e4863e7aab5bd888e26670a00dbda0a9d4687","url":"https://access.redhat.com/errata/RHSA-2025:8560"}},{"version":"4.20.0-rc.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:6f72976d906da6c81ca61d5ef06b62c5afd6e6374049c4e307a2554cf5abef43","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4\\.18\\..*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:6f72976d906da6c81ca61d5ef06b62c5afd6e6374049c4e307a2554cf5abef43","url":"https://access.redhat.com/errata/RHBA-2025:9562"}},{"version":"4.18.0-rc.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5274f17dc4375df73cdeccf43aa4fc268230f1ca2867738f56807d026f2aa8ba","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.]18[.]0-ec[.][0-2][+].*$|4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:5274f17dc4375df73cdeccf43aa4fc268230f1ca2867738f56807d026f2aa8ba","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.20.0-ec.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:7f885da9a26ec7f460a4518a40811c03cf278853186833dc80e96a1ae15c9511","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:7f885da9a26ec7f460a4518a40811c03cf278853186833dc80e96a1ae15c9511"}},{"version":"4.19.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8153a8c010b292c0c4ca7d8b4ca13ebeb634d449982c66568764511c736281b8","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8153a8c010b292c0c4ca7d8b4ca13ebeb634d449982c66568764511c736281b8","url":"https://access.redhat.com/errata/RHSA-2025:10771"}},{"version":"4.18.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:46f9db00dac167897378825ea5f3cce0867743ac90498bbb61b0816daedd0d00","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:46f9db00dac167897378825ea5f3cce0867743ac90498bbb61b0816daedd0d00","url":"https://access.redhat.com/errata/RHBA-2025:1904"}},{"version":"4.19.0-rc.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8970801dee5031571f971bdf922d351f884065ceb3e441c173c8350b3956a229","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8970801dee5031571f971bdf922d351f884065ceb3e441c173c8350b3956a229","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.0-rc.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:23e31abd998aa80ee11344e6ad910d8283d4f2f973c79e9d7fecbd355be459ab","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:23e31abd998aa80ee11344e6ad910d8283d4f2f973c79e9d7fecbd355be459ab","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.0-ec.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:573a86d57acab6dfb90799f568421e80a41f85aaef1e94a16e13af13339524c1","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.](18[.]0-(ec[.].*|rc[.][0-3])|19[.]0-ec[.]0)|.*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:573a86d57acab6dfb90799f568421e80a41f85aaef1e94a16e13af13339524c1"}},{"version":"4.18.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:fdcb3da3a1086d664df31a1fa2a629c77780f844d458af956928cca297da343c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:fdcb3da3a1086d664df31a1fa2a629c77780f844d458af956928cca297da343c","url":"https://access.redhat.com/errata/RHBA-2025:2229"}},{"version":"4.19.13","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b221339d28377e7654ecfa76debf7cd11eccc4e45516cca393df6a5ca4dbc736","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|.*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|4\\.18\\..*|^4[.](18[.][0-9]*|19[.]([0-9]|1[0-2]))[+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:b221339d28377e7654ecfa76debf7cd11eccc4e45516cca393df6a5ca4dbc736","url":"https://access.redhat.com/errata/RHBA-2025:16148"}},{"version":"4.18.18","payload":"quay.io/openshift-release-dev/ocp-release@sha256:eca2e3f7de2bd92b18f69547c8f0ad842fdb83f0821f76b8692f2716a86b0bde","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:eca2e3f7de2bd92b18f69547c8f0ad842fdb83f0821f76b8692f2716a86b0bde","url":"https://access.redhat.com/errata/RHSA-2025:9269"}},{"version":"4.20.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:cbde13fe6ed4db88796be201fbdb2bbb63df5763ae038a9eb20bc793d5740416","metadata":{"io.openshift.upgrades.graph.release.channels":"candidate-4.20,fast-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:cbde13fe6ed4db88796be201fbdb2bbb63df5763ae038a9eb20bc793d5740416","url":"https://access.redhat.com/errata/RHSA-2025:19003"}},{"version":"4.19.0-ec.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:3c7decd8e09329d5206a96bcc19838d25bdc3af9c9565f249aa91494c7beb7db","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.](18[.]0-(ec[.].*|rc[.][0-3])|19[.]0-ec[.]0)|.*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:3c7decd8e09329d5206a96bcc19838d25bdc3af9c9565f249aa91494c7beb7db"}},{"version":"4.18.0-rc.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:668c92b06279cb5c7a2a692860b297eeb9013af10d49d2095f2c3fe9ad02baaa","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:668c92b06279cb5c7a2a692860b297eeb9013af10d49d2095f2c3fe9ad02baaa","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.20.0-ec.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b5bea7566302a82159c42b9fbf37aef3b819cb5a22a9ffd34081b0a2192a071a","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:b5bea7566302a82159c42b9fbf37aef3b819cb5a22a9ffd34081b0a2192a071a"}},{"version":"4.19.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:4d7f10e383deb0c5402f871bf66ebdcad6bb670cb3cf1668bfec5166c56f3196","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:4d7f10e383deb0c5402f871bf66ebdcad6bb670cb3cf1668bfec5166c56f3196","url":"https://access.redhat.com/errata/RHSA-2025:9278"}},{"version":"4.18.0-rc.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:bc8f69a3e79214394c573e331cfd6105a540d79c7f17ae4549fe4dcffd1c8190","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:bc8f69a3e79214394c573e331cfd6105a540d79c7f17ae4549fe4dcffd1c8190","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:61dffd292f6689a3381dd05f7845dcd5d27c099fce2f460aa03d760d535f81e6","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:61dffd292f6689a3381dd05f7845dcd5d27c099fce2f460aa03d760d535f81e6","url":"https://access.redhat.com/errata/RHSA-2025:2449"}},{"version":"4.20.0-rc.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:e7edd14c7b42042bea98f9265af65d7fdbc740e2a6ac4c989d3666a42e06406b","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4\\.18\\..*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:e7edd14c7b42042bea98f9265af65d7fdbc740e2a6ac4c989d3666a42e06406b","url":"https://access.redhat.com/errata/RHBA-2025:9562"}},{"version":"4.18.19","payload":"quay.io/openshift-release-dev/ocp-release@sha256:e6d80b9ab85b17b47e90cb8de1b9ad0e3fe457780148629d329d532ef902d222","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:e6d80b9ab85b17b47e90cb8de1b9ad0e3fe457780148629d329d532ef902d222","url":"https://access.redhat.com/errata/RHSA-2025:9725"}},{"version":"4.19.0-rc.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:6e7c9d6ff30e66f77a84862dba12bee23305139abe4b2bb29f9c796bdf852b7d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:6e7c9d6ff30e66f77a84862dba12bee23305139abe4b2bb29f9c796bdf852b7d","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d9c985464c0315160971b3e79f5fbec628d403a572f7a6d893c04627c066c0bb","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|4[.]18[.]0-ec[.]4[+].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d9c985464c0315160971b3e79f5fbec628d403a572f7a6d893c04627c066c0bb","url":"https://access.redhat.com/errata/RHSA-2024:6122"}},{"version":"4.18.0-rc.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0644a286c7480945553904ef8775bb75ca950287ea1c9ad6cc8ff56890aebc05","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0644a286c7480945553904ef8775bb75ca950287ea1c9ad6cc8ff56890aebc05","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.14","payload":"quay.io/openshift-release-dev/ocp-release@sha256:f8e21e76897b3f9b8a76a07b5a9426ba8def9b2e56b18d8b40ad65931b8bbf78","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|4[.]18[.].*|4\\.18\\..*|^4[.](18[.][0-9]*|19[.]([0-9]|1[0-2]))[+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:f8e21e76897b3f9b8a76a07b5a9426ba8def9b2e56b18d8b40ad65931b8bbf78","url":"https://access.redhat.com/errata/RHBA-2025:16693"}},{"version":"4.20.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0e232879e27fb821eeb1d0e34f9bd8f85e28533836e59cc7fee96fcc9f3851cd","metadata":{"io.openshift.upgrades.graph.release.channels":"candidate-4.20,candidate-4.21","io.openshift.upgrades.graph.release.manifestref":"sha256:0e232879e27fb821eeb1d0e34f9bd8f85e28533836e59cc7fee96fcc9f3851cd","url":"https://access.redhat.com/errata/RHSA-2025:19296"}},{"version":"4.18.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:93879f84b3165c5b5bd1fdf4563a11155dc61ea35cd93e67dc61c2b66e11c8bb","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:93879f84b3165c5b5bd1fdf4563a11155dc61ea35cd93e67dc61c2b66e11c8bb","url":"https://access.redhat.com/errata/RHSA-2025:2705"}},{"version":"4.19.9","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b6f3a6e7cab0bb6e2590f6e6612a3edec75e3b28d32a4e55325bdeeb7d836662","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|4\\.18\\..*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:b6f3a6e7cab0bb6e2590f6e6612a3edec75e3b28d32a4e55325bdeeb7d836662","url":"https://access.redhat.com/errata/RHSA-2025:13848"}},{"version":"4.18.0-rc.6","payload":"quay.io/openshift-release-dev/ocp-release@sha256:1d261c178ac128e85455f370a78f3fea4492cd5c0367888933fe3a5b48c43c84","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:1d261c178ac128e85455f370a78f3fea4492cd5c0367888933fe3a5b48c43c84","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.0-ec.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:1e9baecce90105b4c0aa695dadc2fac7e4b9fd54e0d2ede90e143e57df8e424a","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:1e9baecce90105b4c0aa695dadc2fac7e4b9fd54e0d2ede90e143e57df8e424a"}},{"version":"4.19.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:bc79be35e8b8a3719a3e16c91b64e5945c6c4ff1a9c9d0816339f14e2b004385","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:bc79be35e8b8a3719a3e16c91b64e5945c6c4ff1a9c9d0816339f14e2b004385","url":"https://access.redhat.com/errata/RHSA-2025:11363"}},{"version":"4.18.20","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5e06105a6ba80d04eb5d8d3f9a672fb743ce4710876d99a375c2d9f7b7eaa783","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:5e06105a6ba80d04eb5d8d3f9a672fb743ce4710876d99a375c2d9f7b7eaa783","url":"https://access.redhat.com/errata/RHSA-2025:10767"}},{"version":"4.19.0-ec.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:fde51d1c35425759c83ea0895d0d4fc0f88f6a49a0d080207f15a7bbe3e9982c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:fde51d1c35425759c83ea0895d0d4fc0f88f6a49a0d080207f15a7bbe3e9982c"}},{"version":"4.18.0-rc.7","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2175ebf62c8565098f1628c588c86c99e4418fc7b97b05ee5c803096b03aea90","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2175ebf62c8565098f1628c588c86c99e4418fc7b97b05ee5c803096b03aea90","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.0-rc.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:6fbf12e60c001586c93f9b69d7d24c899503ef401ead5988f82f45cd2d10cba9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:6fbf12e60c001586c93f9b69d7d24c899503ef401ead5988f82f45cd2d10cba9","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.0-ec.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:e930176c384d1c819f6259c403cb9a4fe419eebb1da80a9ae0a0e8afbd74d964","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:e930176c384d1c819f6259c403cb9a4fe419eebb1da80a9ae0a0e8afbd74d964"}},{"version":"4.18.0-rc.8","payload":"quay.io/openshift-release-dev/ocp-release@sha256:f0de3be10be2f5fc1a5b1c208bcfe5d3a71a70989cacbca57ebf7c5fe6e14b09","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:f0de3be10be2f5fc1a5b1c208bcfe5d3a71a70989cacbca57ebf7c5fe6e14b09","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.21","payload":"quay.io/openshift-release-dev/ocp-release@sha256:9d1b107adad76f023493b8c2b74902639f66273cc120e255454ad447a9ef27d9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:9d1b107adad76f023493b8c2b74902639f66273cc120e255454ad447a9ef27d9","url":"https://access.redhat.com/errata/RHSA-2025:11677"}},{"version":"4.18.6","payload":"quay.io/openshift-release-dev/ocp-release@sha256:61fdad894f035a8b192647c224faf565279518255bdbf60a91db4ee0479adaa6","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:61fdad894f035a8b192647c224faf565279518255bdbf60a91db4ee0479adaa6","url":"https://access.redhat.com/errata/RHSA-2025:3066"}},{"version":"4.19.15","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d96bf58288bfe00d347707ba0b9fa5455ee0d506ae4dfe417518473197ee16ab","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|4[.]18[.].*|4\\.18\\..*|^4[.](18[.][0-9]*|19[.]([0-9]|1[0-2]))[+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d96bf58288bfe00d347707ba0b9fa5455ee0d506ae4dfe417518473197ee16ab","url":"https://access.redhat.com/errata/RHBA-2025:17237"}},{"version":"4.19.10","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2f9145136fb387d43c7fff55b30a036c14eb96b0992c292274b6f543c6c33857","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|4\\.18\\..*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2f9145136fb387d43c7fff55b30a036c14eb96b0992c292274b6f543c6c33857","url":"https://access.redhat.com/errata/RHBA-2025:14823"}},{"version":"4.18.7","payload":"quay.io/openshift-release-dev/ocp-release@sha256:91037938dc2ebc2732e7baa6eb4192fa4376abab19f0f545848a87ab7c91931d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:91037938dc2ebc2732e7baa6eb4192fa4376abab19f0f545848a87ab7c91931d","url":"https://access.redhat.com/errata/RHBA-2025:3293"}},{"version":"4.18.0-rc.9","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d59d8a478a51fd9aaf5ddb9a61bb082e38bbd3777d899f9804f256c070e302ae","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d59d8a478a51fd9aaf5ddb9a61bb082e38bbd3777d899f9804f256c070e302ae","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.22","payload":"quay.io/openshift-release-dev/ocp-release@sha256:16078b671c7f5490a2136f2cd9a694d48bb38af1280ef9e2ae9ce28af075cca5","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|^4[.](17[.].*|18[.](1?[0-9]|2[0-1]))[+].*$|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|17[.](([0-9]|[1-2][0-9]|3[0-7])))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:16078b671c7f5490a2136f2cd9a694d48bb38af1280ef9e2ae9ce28af075cca5","url":"https://access.redhat.com/errata/RHSA-2025:13325"}},{"version":"4.19.16","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8f57c0a381695f49c15e4b337f0259a02de2cfa10be3882a6fb795c34217d212","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.](1?[0-9]|2[0-2])|19[.][0-8])[+].*$|4[.]18[.].*|4\\.18\\..*|^4[.](18[.][0-9]*|19[.]([0-9]|1[0-2]))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8f57c0a381695f49c15e4b337f0259a02de2cfa10be3882a6fb795c34217d212","url":"https://access.redhat.com/errata/RHBA-2025:17662"}},{"version":"4.19.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:1293f5ccad2a2776241344faecaf7320f60ee91882df4e24b309f3a7cefc04be","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4\\.18\\..*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:1293f5ccad2a2776241344faecaf7320f60ee91882df4e24b309f3a7cefc04be","url":"https://access.redhat.com/errata/RHSA-2025:9750"}},{"version":"4.18.11","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b3c76706606940d84964095aaab1a8ed4eca0d1bd6833b4eb718115842ef6850","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|.*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:b3c76706606940d84964095aaab1a8ed4eca0d1bd6833b4eb718115842ef6850","url":"https://access.redhat.com/errata/RHSA-2025:4211"}},{"version":"4.18.10","payload":"quay.io/openshift-release-dev/ocp-release@sha256:be8bcea2ab176321a4e1e54caab4709f9024bc437e52ca5bc088e729367cd0cf","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|.*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:be8bcea2ab176321a4e1e54caab4709f9024bc437e52ca5bc088e729367cd0cf","url":"https://access.redhat.com/errata/RHSA-2025:4019"}},{"version":"4.18.8","payload":"quay.io/openshift-release-dev/ocp-release@sha256:509888097ba7d3b4eeb5aac0586acff2ec13fff07004ac692e0dcf5cf4fe2690","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20,fast-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:509888097ba7d3b4eeb5aac0586acff2ec13fff07004ac692e0dcf5cf4fe2690","url":"https://access.redhat.com/errata/RHSA-2025:3577"}}],"edges":[[59,48],[42,48],[16,3],[81,49],[17,24],[75,74],[41,15],[0,18],[19,1],[23,31],[63,68],[48,68],[41,67],[82,4],[81,36],[78,85],[57,74],[81,33],[84,57],[35,74],[84,31],[55,74],[1,4],[59,68],[37,48],[8,31],[85,10],[56,3],[46,68],[47,33],[59,31],[29,37],[24,31],[37,31],[85,48],[9,68],[83,74],[78,48],[76,36],[10,68],[55,57],[71,1],[48,74],[85,68],[76,62],[50,1],[42,74],[10,57],[75,85],[76,33],[63,48],[49,62],[48,57],[10,48],[29,31],[75,48],[80,31],[10,74],[59,57],[52,3],[17,48],[83,31],[78,57],[75,68],[1,82],[83,68],[57,68],[75,31],[61,81],[85,57],[63,31],[29,57],[55,31],[46,48],[9,29],[24,74],[9,37],[75,78],[25,3],[58,1],[67,15],[8,18],[63,57],[74,31],[33,36],[0,23],[42,31],[85,74],[17,68],[9,17],[18,31],[24,48],[63,74],[59,74],[84,48],[17,37],[46,57],[9,48],[83,57],[24,37],[61,36],[78,31],[35,31],[42,57],[0,31],[17,74],[78,68],[47,81],[37,68],[30,1],[17,31],[84,68],[3,49],[24,29],[64,77],[48,31],[33,49],[66,1],[68,31],[76,81],[35,57],[69,1],[9,74],[9,35],[10,31],[24,57],[55,68],[5,3],[29,68],[53,82],[17,35],[46,74],[81,62],[22,1],[18,23],[38,3],[55,48],[35,48],[78,74],[47,36],[29,74],[75,57],[53,4],[61,33],[75,10],[29,48],[9,57],[8,23],[76,3],[7,1],[45,1],[42,68],[28,1],[1,53],[46,31],[35,68],[84,74],[76,49],[0,8],[24,68],[17,57],[21,3],[43,1],[3,62],[37,57],[24,35],[40,3],[13,3],[77,12],[57,31],[85,31],[29,35],[9,24],[9,31],[17,29],[64,12],[33,62],[35,37],[2,3],[37,74],[68,74],[78,10],[83,48]],"conditionalEdges":[{"edges":[{"from":"4.18.22","to":"4.19.17"},{"from":"4.18.25","to":"4.19.17"},{"from":"4.18.26","to":"4.19.17"},{"from":"4.18.24","to":"4.19.18"},{"from":"4.18.23","to":"4.19.18"},{"from":"4.18.20","to":"4.19.17"},{"from":"4.18.27","to":"4.19.18"},{"from":"4.18.24","to":"4.19.16"},{"from":"4.18.25","to":"4.19.16"},{"from":"4.18.23","to":"4.19.16"},{"from":"4.18.26","to":"4.19.16"},{"from":"4.18.26","to":"4.19.18"},{"from":"4.18.24","to":"4.19.17"},{"from":"4.18.19","to":"4.19.17"},{"from":"4.18.19","to":"4.19.18"},{"from":"4.18.22","to":"4.19.18"},{"from":"4.18.21","to":"4.19.18"},{"from":"4.18.23","to":"4.19.17"},{"from":"4.18.21","to":"4.19.17"},{"from":"4.18.20","to":"4.19.18"},{"from":"4.18.25","to":"4.19.18"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.19.11","to":"4.19.15"},{"from":"4.19.10","to":"4.19.15"},{"from":"4.19.12","to":"4.19.15"},{"from":"4.19.9","to":"4.19.14"},{"from":"4.19.12","to":"4.19.14"},{"from":"4.19.10","to":"4.19.14"},{"from":"4.19.9","to":"4.19.15"},{"from":"4.19.11","to":"4.19.14"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.22","to":"4.18.23"}],"risks":[{"url":"https://issues.redhat.com/browse/RUN-3446","name":"CrunConflictsWithNVIDIA","message":"Some crun 1.23 releases conflict with the NVIDIA GPU Operator over eBPF, causing issues with GPU workloads.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (name) (csv_succeeded{_id=\"\", name=~\"gpu-operator-certified[.].*\"})\nor on (_id)\n0 * group(csv_count{_id=\"\"})"}}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.0-ec.4","to":"4.18.0-rc.2"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.3"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.8"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.10"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.9"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.5"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.4"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.0"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.1"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.7"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.6"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1481","name":"MachineConfigServerCARotation","message":"4.18.0-ec.4 adjusted machine-config server CA management.  The change was reverted in 4.18.0-rc.0, but clusters running 4.18.0-ec.4 need manual steps to be able to scale new Machines.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.20","to":"4.19.6"},{"from":"4.18.20","to":"4.19.5"},{"from":"4.18.21","to":"4.19.6"},{"from":"4.18.19","to":"4.19.6"},{"from":"4.18.19","to":"4.19.5"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.24","to":"4.19.14"},{"from":"4.18.24","to":"4.19.15"},{"from":"4.18.25","to":"4.19.15"},{"from":"4.18.23","to":"4.19.15"},{"from":"4.18.23","to":"4.19.14"},{"from":"4.18.25","to":"4.19.14"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.22","to":"4.19.10"},{"from":"4.18.22","to":"4.19.11"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.20","to":"4.19.4"},{"from":"4.18.19","to":"4.19.4"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1110","name":"HCPServiceHealthCheckDisruption","message":"When Hosted Control Plane (HCP/HyperShift) clusters running on AWS update a node pool, the Services of type\nLoadBalancer may experience temporary availability disruption because health checks are not set up properly to monitor\nNode readiness state.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\n  or\n  0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\n* on (_id) group_left (type) (\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3357","name":"OldBootImagesComposeFSvsGrubProbe","message":"Upgrade to 4.19 will fail due to a boot image incompatibility issue if a cluster was born in 4.2 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  label_replace(group by (version) (cluster_version{_id=\"\",type=\"initial\",version=~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"yes, so possibly actually born in 4.2 or earlier\", \"\", \"\")\n  or\n  label_replace(0 * group by (version) (cluster_version{_id=\"\",type=\"initial\",version!~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"no, born in 4.10 or later\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.18.1","to":"4.18.8"},{"from":"4.18.4","to":"4.18.8"},{"from":"4.18.3","to":"4.18.8"},{"from":"4.18.2","to":"4.18.9"},{"from":"4.18.5","to":"4.18.8"},{"from":"4.18.3","to":"4.18.7"},{"from":"4.18.2","to":"4.18.8"},{"from":"4.18.4","to":"4.18.9"},{"from":"4.18.3","to":"4.18.9"},{"from":"4.18.5","to":"4.18.9"},{"from":"4.18.1","to":"4.18.9"},{"from":"4.18.4","to":"4.18.7"},{"from":"4.18.2","to":"4.18.7"},{"from":"4.18.1","to":"4.18.7"},{"from":"4.18.5","to":"4.18.7"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.7","to":"4.19.14"},{"from":"4.19.4","to":"4.19.14"},{"from":"4.19.3","to":"4.19.14"},{"from":"4.19.4","to":"4.19.15"},{"from":"4.19.5","to":"4.19.15"},{"from":"4.19.1","to":"4.19.14"},{"from":"4.19.2","to":"4.19.15"},{"from":"4.19.1","to":"4.19.15"},{"from":"4.19.5","to":"4.19.14"},{"from":"4.19.7","to":"4.19.15"},{"from":"4.19.6","to":"4.19.14"},{"from":"4.19.0","to":"4.19.15"},{"from":"4.19.2","to":"4.19.14"},{"from":"4.19.3","to":"4.19.15"},{"from":"4.19.6","to":"4.19.15"},{"from":"4.19.0","to":"4.19.14"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.4","to":"4.19.13"},{"from":"4.19.5","to":"4.19.13"},{"from":"4.19.6","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.23","to":"4.19.11"},{"from":"4.18.23","to":"4.19.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.0-ec.3","to":"4.18.1"},{"from":"4.18.0-rc.0","to":"4.18.1"},{"from":"4.18.0-rc.2","to":"4.18.1"},{"from":"4.18.0-rc.3","to":"4.18.1"},{"from":"4.18.0-rc.1","to":"4.18.1"},{"from":"4.18.0-rc.10","to":"4.18.1"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.19.7","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.22","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.21","to":"4.19.10"},{"from":"4.18.19","to":"4.19.11"},{"from":"4.18.20","to":"4.19.10"},{"from":"4.18.19","to":"4.19.10"},{"from":"4.18.20","to":"4.19.11"},{"from":"4.18.21","to":"4.19.11"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.19","to":"4.19.3"},{"from":"4.18.18","to":"4.19.3"},{"from":"4.18.17","to":"4.19.3"},{"from":"4.18.16","to":"4.19.3"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1109","name":"HCPMetallbCNOCannotDeployFRRK8S","message":"On Hosted Control Plane (HCP/HyperShift) clusters with installed MetalLB operator, Cluster Network Operator fails to\ndeploy a critical component FRR-k8s when updated. MetalLB will stop working properly and stop advertising services,\nmaking them potentially unreachable from outside the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\ngroup by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\nand on (_id) (\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n)\nor on (_id) (\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1110","name":"HCPServiceHealthCheckDisruption","message":"When Hosted Control Plane (HCP/HyperShift) clusters running on AWS update a node pool, the Services of type\nLoadBalancer may experience temporary availability disruption because health checks are not set up properly to monitor\nNode readiness state.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\n  or\n  0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\n* on (_id) group_left (type) (\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3357","name":"OldBootImagesComposeFSvsGrubProbe","message":"Upgrade to 4.19 will fail due to a boot image incompatibility issue if a cluster was born in 4.2 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  label_replace(group by (version) (cluster_version{_id=\"\",type=\"initial\",version=~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"yes, so possibly actually born in 4.2 or earlier\", \"\", \"\")\n  or\n  label_replace(0 * group by (version) (cluster_version{_id=\"\",type=\"initial\",version!~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"no, born in 4.10 or later\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.19.7","to":"4.19.10"},{"from":"4.19.7","to":"4.19.11"},{"from":"4.19.7","to":"4.19.9"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.20","to":"4.19.15"},{"from":"4.18.22","to":"4.19.15"},{"from":"4.18.21","to":"4.19.14"},{"from":"4.18.19","to":"4.19.15"},{"from":"4.18.19","to":"4.19.14"},{"from":"4.18.20","to":"4.19.14"},{"from":"4.18.21","to":"4.19.15"},{"from":"4.18.22","to":"4.19.14"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.10","to":"4.20.0-rc.1"},{"from":"4.19.4","to":"4.20.0-rc.0"},{"from":"4.20.0-ec.5","to":"4.20.0-rc.2"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.7"},{"from":"4.20.0-ec.3","to":"4.20.0-rc.1"},{"from":"4.20.0-ec.3","to":"4.20.0-ec.5"},{"from":"4.20.0-rc.2","to":"4.20.0-rc.3"},{"from":"4.19.0","to":"4.20.0-ec.6"},{"from":"4.19.0-rc.2","to":"4.19.0-rc.4"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.4"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.0"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.2"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.1"},{"from":"4.18.0-rc.7","to":"4.18.0-rc.9"},{"from":"4.20.0-ec.6","to":"4.20.0-rc.3"},{"from":"4.19.0-rc.0","to":"4.20.0-ec.0"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.8"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.5"},{"from":"4.19.0-rc.3","to":"4.19.0-rc.4"},{"from":"4.19.0-rc.2","to":"4.20.0-ec.2"},{"from":"4.19.2","to":"4.20.0-rc.0"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.6"},{"from":"4.19.9","to":"4.20.0-rc.2"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.4"},{"from":"4.19.0-rc.4","to":"4.19.0-rc.5"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.1"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.4"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.10"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.2"},{"from":"4.19.5","to":"4.20.0-ec.5"},{"from":"4.19.0-rc.4","to":"4.20.0-ec.2"},{"from":"4.20.0-ec.6","to":"4.20.0-rc.1"},{"from":"4.19.0-rc.2","to":"4.19.0-rc.3"},{"from":"4.20.0-ec.6","to":"4.20.0-rc.0"},{"from":"4.19.9","to":"4.20.0-rc.1"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.1"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.4"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.3"},{"from":"4.19.5","to":"4.20.0-ec.6"},{"from":"4.19.0","to":"4.20.0-rc.2"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.10"},{"from":"4.20.0-ec.0","to":"4.20.0-ec.3"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.1"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.1"},{"from":"4.20.0-ec.0","to":"4.20.0-rc.1"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.6"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.6"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.6"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.3"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.5"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.4"},{"from":"4.20.0-ec.4","to":"4.20.0-rc.1"},{"from":"4.19.7","to":"4.20.0-rc.0"},{"from":"4.19.9","to":"4.20.0-ec.6"},{"from":"4.19.9","to":"4.20.0-rc.3"},{"from":"4.19.0-ec.2","to":"4.19.0-ec.4"},{"from":"4.20.0-ec.0","to":"4.20.0-rc.3"},{"from":"4.19.5","to":"4.20.0-rc.1"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.8"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.2"},{"from":"4.20.0-ec.3","to":"4.20.0-rc.3"},{"from":"4.19.0","to":"4.20.0-rc.1"},{"from":"4.18.0-rc.7","to":"4.18.0-rc.10"},{"from":"4.18.0-ec.3","to":"4.18.0-ec.4"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.5"},{"from":"4.20.0-ec.2","to":"4.20.0-rc.2"},{"from":"4.19.0-ec.2","to":"4.19.0-ec.3"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.2"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.5"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.5"},{"from":"4.19.2","to":"4.20.0-ec.5"},{"from":"4.19.2","to":"4.20.0-ec.4"},{"from":"4.20.0-ec.0","to":"4.20.0-ec.4"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.2"},{"from":"4.19.0-rc.1","to":"4.20.0-ec.2"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.4"},{"from":"4.18.0-rc.9","to":"4.18.0-rc.10"},{"from":"4.19.0-rc.3","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.9"},{"from":"4.20.0-ec.4","to":"4.20.0-rc.0"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.3"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.9"},{"from":"4.19.13","to":"4.20.0-rc.3"},{"from":"4.20.0-ec.5","to":"4.20.0-rc.3"},{"from":"4.19.7","to":"4.20.0-rc.3"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.0"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.3"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.7"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.5"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.3"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.10"},{"from":"4.20.0-ec.2","to":"4.20.0-rc.0"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.9"},{"from":"4.20.0-ec.2","to":"4.20.0-ec.5"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.1"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.2"},{"from":"4.19.0-ec.2","to":"4.19.0-ec.5"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.5"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.0"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.0"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.3"},{"from":"4.19.1","to":"4.20.0-rc.1"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.7"},{"from":"4.18.0-rc.8","to":"4.18.0-rc.10"},{"from":"4.19.4","to":"4.20.0-ec.6"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.3"},{"from":"4.19.5","to":"4.20.0-rc.3"},{"from":"4.19.11","to":"4.20.0-rc.2"},{"from":"4.19.10","to":"4.20.0-rc.3"},{"from":"4.19.9","to":"4.20.0-rc.0"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.10"},{"from":"4.19.5","to":"4.20.0-rc.0"},{"from":"4.19.1","to":"4.20.0-ec.6"},{"from":"4.20.0-ec.3","to":"4.20.0-ec.6"},{"from":"4.19.6","to":"4.20.0-rc.2"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.6"},{"from":"4.19.3","to":"4.20.0-rc.2"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.2"},{"from":"4.19.1","to":"4.20.0-ec.5"},{"from":"4.19.0","to":"4.20.0-rc.3"},{"from":"4.19.1","to":"4.20.0-rc.3"},{"from":"4.20.0-rc.0","to":"4.20.0-rc.3"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.5"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.3"},{"from":"4.20.0-ec.5","to":"4.20.0-ec.6"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.7"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.4"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.2"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.10"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.10"},{"from":"4.19.0-rc.2","to":"4.19.0-rc.5"},{"from":"4.20.0-ec.4","to":"4.20.0-ec.5"},{"from":"4.20.0-ec.0","to":"4.20.0-ec.2"},{"from":"4.20.0-ec.5","to":"4.20.0-rc.1"},{"from":"4.20.0-ec.0","to":"4.20.0-rc.0"},{"from":"4.19.4","to":"4.20.0-rc.2"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.1"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.5"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.9"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.4"},{"from":"4.20.0-ec.2","to":"4.20.0-rc.3"},{"from":"4.19.6","to":"4.20.0-rc.3"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.10"},{"from":"4.20.0-ec.3","to":"4.20.0-rc.0"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.8"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.0"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.4"},{"from":"4.19.2","to":"4.20.0-ec.6"},{"from":"4.19.0-rc.0","to":"4.20.0-ec.2"},{"from":"4.19.6","to":"4.20.0-rc.1"},{"from":"4.19.5","to":"4.20.0-rc.2"},{"from":"4.19.3","to":"4.20.0-rc.0"},{"from":"4.20.0-ec.2","to":"4.20.0-ec.4"},{"from":"4.20.0-rc.0","to":"4.20.0-rc.2"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.2"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.0"},{"from":"4.20.0-rc.0","to":"4.20.0-rc.1"},{"from":"4.19.2","to":"4.20.0-rc.1"},{"from":"4.19.3","to":"4.20.0-rc.1"},{"from":"4.19.14","to":"4.20.0-rc.3"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.4"},{"from":"4.19.10","to":"4.20.0-rc.2"},{"from":"4.19.3","to":"4.20.0-ec.5"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.2"},{"from":"4.20.0-rc.1","to":"4.20.0-rc.3"},{"from":"4.20.0-ec.2","to":"4.20.0-ec.3"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.7"},{"from":"4.19.6","to":"4.20.0-ec.6"},{"from":"4.20.0-ec.2","to":"4.20.0-rc.1"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.8"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.3"},{"from":"4.20.0-rc.1","to":"4.20.0-rc.2"},{"from":"4.19.0-ec.4","to":"4.19.0-ec.5"},{"from":"4.20.0-ec.0","to":"4.20.0-ec.6"},{"from":"4.20.0-ec.4","to":"4.20.0-rc.3"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.7"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.2"},{"from":"4.18.0-rc.8","to":"4.18.0-rc.9"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.1"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.8"},{"from":"4.19.1","to":"4.20.0-rc.0"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.7"},{"from":"4.19.12","to":"4.20.0-rc.3"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.2"},{"from":"4.19.2","to":"4.20.0-rc.3"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.8"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.5"},{"from":"4.19.0-rc.3","to":"4.20.0-ec.2"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.5"},{"from":"4.19.1","to":"4.20.0-ec.3"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.1"},{"from":"4.19.0","to":"4.20.0-ec.4"},{"from":"4.19.11","to":"4.20.0-rc.1"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.3"},{"from":"4.19.4","to":"4.20.0-rc.3"},{"from":"4.20.0-ec.0","to":"4.20.0-rc.2"},{"from":"4.20.0-ec.5","to":"4.20.0-rc.0"},{"from":"4.19.0-ec.3","to":"4.19.0-ec.5"},{"from":"4.19.7","to":"4.20.0-rc.1"},{"from":"4.19.4","to":"4.20.0-ec.5"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.9"},{"from":"4.19.0","to":"4.20.0-ec.3"},{"from":"4.19.0","to":"4.20.0-rc.0"},{"from":"4.20.0-ec.6","to":"4.20.0-rc.2"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.3"},{"from":"4.19.6","to":"4.20.0-ec.5"},{"from":"4.19.3","to":"4.20.0-ec.4"},{"from":"4.19.7","to":"4.20.0-rc.2"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.6"},{"from":"4.19.6","to":"4.20.0-rc.0"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.8"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.5"},{"from":"4.19.3","to":"4.20.0-rc.3"},{"from":"4.19.2","to":"4.20.0-rc.2"},{"from":"4.19.0-ec.3","to":"4.19.0-ec.4"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.4"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.3"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.5"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.4"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.10"},{"from":"4.19.1","to":"4.20.0-ec.4"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.4"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.9"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.5"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.3"},{"from":"4.20.0-ec.2","to":"4.20.0-ec.6"},{"from":"4.19.4","to":"4.20.0-rc.1"},{"from":"4.20.0-ec.4","to":"4.20.0-rc.2"},{"from":"4.19.0","to":"4.20.0-ec.5"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.2"},{"from":"4.20.0-ec.3","to":"4.20.0-rc.2"},{"from":"4.19.3","to":"4.20.0-ec.6"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.7"},{"from":"4.20.0-ec.0","to":"4.20.0-ec.5"},{"from":"4.19.1","to":"4.20.0-rc.2"},{"from":"4.19.10","to":"4.20.0-rc.0"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.0"},{"from":"4.20.0-ec.3","to":"4.20.0-ec.4"},{"from":"4.20.0-ec.4","to":"4.20.0-ec.6"},{"from":"4.19.11","to":"4.20.0-rc.3"},{"from":"4.18.0-ec.1","to":"4.18.0-ec.2"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.8"},{"from":"4.19.7","to":"4.20.0-ec.6"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.6"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.19","to":"4.19.9"},{"from":"4.18.21","to":"4.19.9"},{"from":"4.18.20","to":"4.19.9"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.9","to":"4.18.23"},{"from":"4.18.17","to":"4.18.23"},{"from":"4.18.14","to":"4.18.23"},{"from":"4.18.6","to":"4.18.23"},{"from":"4.18.21","to":"4.18.23"},{"from":"4.18.13","to":"4.18.23"},{"from":"4.18.10","to":"4.18.23"},{"from":"4.18.8","to":"4.18.23"},{"from":"4.18.18","to":"4.18.23"},{"from":"4.18.15","to":"4.18.23"},{"from":"4.18.5","to":"4.18.23"},{"from":"4.18.16","to":"4.18.23"},{"from":"4.18.2","to":"4.18.23"},{"from":"4.18.20","to":"4.18.23"},{"from":"4.18.7","to":"4.18.23"},{"from":"4.18.1","to":"4.18.23"},{"from":"4.18.3","to":"4.18.23"},{"from":"4.18.4","to":"4.18.23"},{"from":"4.18.11","to":"4.18.23"},{"from":"4.18.19","to":"4.18.23"},{"from":"4.18.12","to":"4.18.23"}],"risks":[{"url":"https://issues.redhat.com/browse/RUN-3446","name":"CrunConflictsWithNVIDIA","message":"Some crun 1.23 releases conflict with the NVIDIA GPU Operator over eBPF, causing issues with GPU workloads.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (name) (csv_succeeded{_id=\"\", name=~\"gpu-operator-certified[.].*\"})\nor on (_id)\n0 * group(csv_count{_id=\"\"})"}}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.7","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.20","to":"4.19.16"},{"from":"4.18.22","to":"4.19.16"},{"from":"4.18.19","to":"4.19.16"},{"from":"4.18.21","to":"4.19.16"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.19.13","to":"4.19.14"},{"from":"4.19.14","to":"4.19.15"},{"from":"4.19.16","to":"4.20.0"},{"from":"4.19.13","to":"4.19.15"},{"from":"4.19.17","to":"4.20.0"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.3","to":"4.19.5"},{"from":"4.19.1","to":"4.19.5"},{"from":"4.19.0","to":"4.19.6"},{"from":"4.19.2","to":"4.19.4"},{"from":"4.19.1","to":"4.19.6"},{"from":"4.19.0","to":"4.19.5"},{"from":"4.19.3","to":"4.19.4"},{"from":"4.19.0","to":"4.19.4"},{"from":"4.19.2","to":"4.19.6"},{"from":"4.19.3","to":"4.19.6"},{"from":"4.19.2","to":"4.19.5"},{"from":"4.19.1","to":"4.19.4"}],"risks":[{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.22","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.16","to":"4.18.22"},{"from":"4.18.11","to":"4.18.22"},{"from":"4.18.21","to":"4.18.22"},{"from":"4.18.8","to":"4.18.22"},{"from":"4.18.14","to":"4.18.22"},{"from":"4.18.7","to":"4.18.22"},{"from":"4.18.3","to":"4.18.22"},{"from":"4.18.17","to":"4.18.22"},{"from":"4.18.10","to":"4.18.22"},{"from":"4.18.20","to":"4.18.22"},{"from":"4.18.9","to":"4.18.22"},{"from":"4.18.5","to":"4.18.22"},{"from":"4.18.13","to":"4.18.22"},{"from":"4.18.15","to":"4.18.22"},{"from":"4.18.6","to":"4.18.22"},{"from":"4.18.2","to":"4.18.22"},{"from":"4.18.18","to":"4.18.22"},{"from":"4.18.12","to":"4.18.22"},{"from":"4.18.4","to":"4.18.22"},{"from":"4.18.19","to":"4.18.22"},{"from":"4.18.1","to":"4.18.22"}],"risks":[{"url":"https://issues.redhat.com/browse/RUN-3446","name":"CrunConflictsWithNVIDIA","message":"Some crun 1.23 releases conflict with the NVIDIA GPU Operator over eBPF, causing issues with GPU workloads.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (name) (csv_succeeded{_id=\"\", name=~\"gpu-operator-certified[.].*\"})\nor on (_id)\n0 * group(csv_count{_id=\"\"})"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.0-rc.2","to":"4.19.0-ec.1"},{"from":"4.18.0-rc.1","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.3","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.3","to":"4.19.0-ec.1"},{"from":"4.18.0-rc.1","to":"4.19.0-ec.1"},{"from":"4.18.0-rc.2","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.0","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.0","to":"4.19.0-ec.1"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/STOR-2486","name":"VSphereStorageMountIssues","message":"vSphere customers using vSAN file volumes can't mount vSphere shared volumes and NFS volumes which server do not set NFS4ERR_ATTRNOTSUPP","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_infrastructure_provider{type=~\"VSphere|None\"})\nor\n0 * group(cluster_infrastructure_provider)\n"}}]}]},{"edges":[{"from":"4.19.7","to":"4.19.16"},{"from":"4.19.2","to":"4.19.16"},{"from":"4.19.5","to":"4.19.16"},{"from":"4.19.1","to":"4.19.16"},{"from":"4.19.6","to":"4.19.16"},{"from":"4.19.4","to":"4.19.16"},{"from":"4.19.0","to":"4.19.16"},{"from":"4.19.3","to":"4.19.16"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.18.8","to":"4.18.11"},{"from":"4.18.8","to":"4.18.10"},{"from":"4.18.9","to":"4.18.10"},{"from":"4.18.6","to":"4.18.10"},{"from":"4.18.7","to":"4.18.11"},{"from":"4.18.7","to":"4.18.10"},{"from":"4.18.9","to":"4.18.11"},{"from":"4.18.6","to":"4.18.11"},{"from":"4.18.10","to":"4.18.11"}],"risks":[{"url":"https://issues.redhat.com/browse/CNF-17689","name":"MetallbBgpBfdFrrRpm","message":"Clusters using MetalLB BFD capabilities alongside BGP can fail to establish BGP peering, reducing the availability of LoadBalancer services exposed by MetalLB, or even making them unreachable","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]}]},{"edges":[{"from":"4.19.2","to":"4.19.10"},{"from":"4.19.3","to":"4.19.10"},{"from":"4.19.3","to":"4.19.11"},{"from":"4.19.0","to":"4.19.9"},{"from":"4.19.0","to":"4.19.11"},{"from":"4.19.2","to":"4.19.9"},{"from":"4.19.1","to":"4.19.11"},{"from":"4.19.1","to":"4.19.9"},{"from":"4.19.3","to":"4.19.9"},{"from":"4.19.1","to":"4.19.10"},{"from":"4.19.2","to":"4.19.11"},{"from":"4.19.0","to":"4.19.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.19","to":"4.19.13"},{"from":"4.18.20","to":"4.19.13"},{"from":"4.18.21","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.2","to":"4.18.11"},{"from":"4.18.3","to":"4.18.10"},{"from":"4.18.1","to":"4.18.11"},{"from":"4.18.2","to":"4.18.10"},{"from":"4.18.4","to":"4.18.10"},{"from":"4.18.3","to":"4.18.11"},{"from":"4.18.4","to":"4.18.11"},{"from":"4.18.1","to":"4.18.10"},{"from":"4.18.5","to":"4.18.10"},{"from":"4.18.5","to":"4.18.11"}],"risks":[{"url":"https://issues.redhat.com/browse/CNF-17689","name":"MetallbBgpBfdFrrRpm","message":"Clusters using MetalLB BFD capabilities alongside BGP can fail to establish BGP peering, reducing the availability of LoadBalancer services exposed by MetalLB, or even making them unreachable","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.10","to":"4.19.12"},{"from":"4.19.9","to":"4.19.12"},{"from":"4.19.11","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.9","to":"4.19.13"},{"from":"4.19.10","to":"4.19.13"},{"from":"4.19.12","to":"4.19.13"},{"from":"4.19.11","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.5","to":"4.19.7"},{"from":"4.19.6","to":"4.19.7"},{"from":"4.19.4","to":"4.19.7"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.24","to":"4.19.13"},{"from":"4.18.23","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.5","to":"4.18.6"},{"from":"4.18.3","to":"4.18.6"},{"from":"4.18.1","to":"4.18.6"},{"from":"4.18.4","to":"4.18.6"},{"from":"4.18.2","to":"4.18.6"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.2","to":"4.18.15"},{"from":"4.18.5","to":"4.18.14"},{"from":"4.18.1","to":"4.18.14"},{"from":"4.18.3","to":"4.18.12"},{"from":"4.18.5","to":"4.18.16"},{"from":"4.18.1","to":"4.18.13"},{"from":"4.18.5","to":"4.18.15"},{"from":"4.18.5","to":"4.18.12"},{"from":"4.18.4","to":"4.18.15"},{"from":"4.18.2","to":"4.18.13"},{"from":"4.18.2","to":"4.18.12"},{"from":"4.18.2","to":"4.18.16"},{"from":"4.18.4","to":"4.18.14"},{"from":"4.18.3","to":"4.18.14"},{"from":"4.18.3","to":"4.18.16"},{"from":"4.18.4","to":"4.18.12"},{"from":"4.18.1","to":"4.18.15"},{"from":"4.18.3","to":"4.18.13"},{"from":"4.18.1","to":"4.18.12"},{"from":"4.18.3","to":"4.18.15"},{"from":"4.18.4","to":"4.18.13"},{"from":"4.18.5","to":"4.18.13"},{"from":"4.18.1","to":"4.18.16"},{"from":"4.18.2","to":"4.18.14"},{"from":"4.18.4","to":"4.18.16"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4632","name":"ConsoleEnabledTargetDownAlert","message":"The alert TargetDown is triggered if the capability Console is enabled on the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"max(cluster_version_capability{name=\"Console\"})"}}]},{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.0-rc.6","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.9","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.7","to":"4.19.0-ec.2"},{"from":"4.18.2","to":"4.19.0-ec.3"},{"from":"4.18.10","to":"4.19.0-ec.5"},{"from":"4.18.0-rc.4","to":"4.19.0-ec.1"},{"from":"4.18.7","to":"4.19.0-ec.4"},{"from":"4.18.15","to":"4.19.0-rc.4"},{"from":"4.18.13","to":"4.19.0-rc.3"},{"from":"4.18.0-rc.1","to":"4.19.0-ec.0"},{"from":"4.18.0-rc.5","to":"4.19.0-ec.2"},{"from":"4.18.17","to":"4.19.0-rc.5"},{"from":"4.18.13","to":"4.19.0-rc.2"},{"from":"4.18.16","to":"4.19.0-rc.4"},{"from":"4.18.3","to":"4.19.0-ec.3"},{"from":"4.18.1","to":"4.19.0-ec.3"},{"from":"4.18.13","to":"4.19.0-rc.1"},{"from":"4.18.9","to":"4.19.0-ec.5"},{"from":"4.18.8","to":"4.19.0-ec.5"},{"from":"4.18.13","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.8","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.0","to":"4.19.0-ec.0"},{"from":"4.18.14","to":"4.19.0-rc.2"},{"from":"4.18.6","to":"4.19.0-ec.5"},{"from":"4.18.16","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.5","to":"4.19.0-ec.1"},{"from":"4.18.13","to":"4.19.0-rc.0"},{"from":"4.18.7","to":"4.19.0-ec.5"},{"from":"4.18.6","to":"4.19.0-ec.4"},{"from":"4.18.14","to":"4.19.0-rc.3"},{"from":"4.18.14","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.4","to":"4.19.0-ec.2"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/STOR-2486","name":"VSphereStorageMountIssues","message":"vSphere customers using vSAN file volumes can't mount vSphere shared volumes and NFS volumes which server do not set NFS4ERR_ATTRNOTSUPP","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_infrastructure_provider{type=~\"VSphere|None\"})\nor\n0 * group(cluster_infrastructure_provider)\n"}}]}]},{"edges":[{"from":"4.19.3","to":"4.19.13"},{"from":"4.19.2","to":"4.19.13"},{"from":"4.19.1","to":"4.19.13"},{"from":"4.19.0","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.0","to":"4.19.7"},{"from":"4.19.1","to":"4.19.7"},{"from":"4.19.3","to":"4.19.7"},{"from":"4.19.2","to":"4.19.7"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.4","to":"4.19.10"},{"from":"4.19.4","to":"4.19.11"},{"from":"4.19.5","to":"4.19.11"},{"from":"4.19.6","to":"4.19.9"},{"from":"4.19.6","to":"4.19.10"},{"from":"4.19.5","to":"4.19.9"},{"from":"4.19.4","to":"4.19.9"},{"from":"4.19.6","to":"4.19.11"},{"from":"4.19.5","to":"4.19.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.15","to":"4.18.25"},{"from":"4.18.16","to":"4.18.25"},{"from":"4.18.6","to":"4.18.25"},{"from":"4.18.8","to":"4.18.25"},{"from":"4.18.16","to":"4.18.26"},{"from":"4.18.21","to":"4.18.25"},{"from":"4.18.19","to":"4.18.26"},{"from":"4.18.6","to":"4.18.26"},{"from":"4.18.14","to":"4.18.26"},{"from":"4.18.1","to":"4.18.26"},{"from":"4.18.19","to":"4.18.25"},{"from":"4.18.22","to":"4.18.25"},{"from":"4.18.13","to":"4.18.25"},{"from":"4.18.11","to":"4.18.26"},{"from":"4.18.21","to":"4.18.26"},{"from":"4.18.20","to":"4.18.25"},{"from":"4.18.7","to":"4.18.26"},{"from":"4.18.9","to":"4.18.26"},{"from":"4.18.22","to":"4.18.24"},{"from":"4.18.4","to":"4.18.25"},{"from":"4.18.1","to":"4.18.25"},{"from":"4.18.13","to":"4.18.26"},{"from":"4.18.3","to":"4.18.25"},{"from":"4.18.9","to":"4.18.25"},{"from":"4.18.11","to":"4.18.25"},{"from":"4.18.10","to":"4.18.26"},{"from":"4.18.17","to":"4.18.26"},{"from":"4.18.14","to":"4.18.25"},{"from":"4.18.17","to":"4.18.25"},{"from":"4.18.18","to":"4.18.25"},{"from":"4.18.5","to":"4.18.26"},{"from":"4.18.4","to":"4.18.26"},{"from":"4.18.8","to":"4.18.26"},{"from":"4.18.3","to":"4.18.26"},{"from":"4.18.15","to":"4.18.26"},{"from":"4.18.22","to":"4.18.26"},{"from":"4.18.12","to":"4.18.26"},{"from":"4.18.2","to":"4.18.26"},{"from":"4.18.12","to":"4.18.25"},{"from":"4.18.2","to":"4.18.25"},{"from":"4.18.18","to":"4.18.26"},{"from":"4.18.7","to":"4.18.25"},{"from":"4.18.10","to":"4.18.25"},{"from":"4.18.5","to":"4.18.25"},{"from":"4.18.20","to":"4.18.26"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.11","to":"4.18.24"},{"from":"4.18.13","to":"4.18.24"},{"from":"4.18.6","to":"4.18.24"},{"from":"4.18.15","to":"4.18.24"},{"from":"4.18.10","to":"4.18.24"},{"from":"4.18.17","to":"4.18.24"},{"from":"4.18.5","to":"4.18.24"},{"from":"4.18.20","to":"4.18.24"},{"from":"4.18.1","to":"4.18.24"},{"from":"4.18.18","to":"4.18.24"},{"from":"4.18.9","to":"4.18.24"},{"from":"4.18.4","to":"4.18.24"},{"from":"4.18.16","to":"4.18.24"},{"from":"4.18.8","to":"4.18.24"},{"from":"4.18.12","to":"4.18.24"},{"from":"4.18.3","to":"4.18.24"},{"from":"4.18.7","to":"4.18.24"},{"from":"4.18.14","to":"4.18.24"},{"from":"4.18.19","to":"4.18.24"},{"from":"4.18.2","to":"4.18.24"},{"from":"4.18.21","to":"4.18.24"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.23","to":"4.19.12"},{"from":"4.18.24","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.19","to":"4.19.7"},{"from":"4.18.20","to":"4.19.7"},{"from":"4.18.21","to":"4.19.7"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.6","to":"4.18.15"},{"from":"4.18.8","to":"4.18.12"},{"from":"4.18.6","to":"4.18.14"},{"from":"4.18.7","to":"4.18.15"},{"from":"4.18.11","to":"4.18.14"},{"from":"4.18.11","to":"4.18.13"},{"from":"4.18.6","to":"4.18.13"},{"from":"4.18.2","to":"4.18.17"},{"from":"4.18.11","to":"4.18.12"},{"from":"4.18.10","to":"4.18.14"},{"from":"4.18.11","to":"4.18.16"},{"from":"4.18.11","to":"4.18.15"},{"from":"4.18.1","to":"4.18.17"},{"from":"4.18.6","to":"4.18.16"},{"from":"4.18.9","to":"4.18.15"},{"from":"4.18.3","to":"4.18.17"},{"from":"4.18.6","to":"4.18.17"},{"from":"4.18.9","to":"4.18.17"},{"from":"4.18.10","to":"4.18.17"},{"from":"4.18.7","to":"4.18.12"},{"from":"4.18.7","to":"4.18.13"},{"from":"4.18.11","to":"4.18.17"},{"from":"4.18.9","to":"4.18.16"},{"from":"4.18.8","to":"4.18.14"},{"from":"4.18.10","to":"4.18.12"},{"from":"4.18.9","to":"4.18.12"},{"from":"4.18.8","to":"4.18.17"},{"from":"4.18.9","to":"4.18.14"},{"from":"4.18.7","to":"4.18.17"},{"from":"4.18.7","to":"4.18.14"},{"from":"4.18.10","to":"4.18.16"},{"from":"4.18.8","to":"4.18.15"},{"from":"4.18.8","to":"4.18.16"},{"from":"4.18.8","to":"4.18.13"},{"from":"4.18.10","to":"4.18.15"},{"from":"4.18.6","to":"4.18.12"},{"from":"4.18.10","to":"4.18.13"},{"from":"4.18.7","to":"4.18.16"},{"from":"4.18.9","to":"4.18.13"},{"from":"4.18.5","to":"4.18.17"},{"from":"4.18.4","to":"4.18.17"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4632","name":"ConsoleEnabledTargetDownAlert","message":"The alert TargetDown is triggered if the capability Console is enabled on the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"max(cluster_version_capability{name=\"Console\"})"}}]}]},{"edges":[{"from":"4.18.19","to":"4.19.2"},{"from":"4.18.18","to":"4.19.2"},{"from":"4.18.16","to":"4.19.2"},{"from":"4.18.17","to":"4.19.1"},{"from":"4.18.17","to":"4.19.0"},{"from":"4.18.18","to":"4.19.1"},{"from":"4.18.16","to":"4.19.1"},{"from":"4.18.16","to":"4.19.0"},{"from":"4.18.17","to":"4.19.2"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1109","name":"HCPMetallbCNOCannotDeployFRRK8S","message":"On Hosted Control Plane (HCP/HyperShift) clusters with installed MetalLB operator, Cluster Network Operator fails to\ndeploy a critical component FRR-k8s when updated. MetalLB will stop working properly and stop advertising services,\nmaking them potentially unreachable from outside the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\ngroup by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\nand on (_id) (\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n)\nor on (_id) (\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1110","name":"HCPServiceHealthCheckDisruption","message":"When Hosted Control Plane (HCP/HyperShift) clusters running on AWS update a node pool, the Services of type\nLoadBalancer may experience temporary availability disruption because health checks are not set up properly to monitor\nNode readiness state.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\n  or\n  0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\n* on (_id) group_left (type) (\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3357","name":"OldBootImagesComposeFSvsGrubProbe","message":"Upgrade to 4.19 will fail due to a boot image incompatibility issue if a cluster was born in 4.2 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  label_replace(group by (version) (cluster_version{_id=\"\",type=\"initial\",version=~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"yes, so possibly actually born in 4.2 or earlier\", \"\", \"\")\n  or\n  label_replace(0 * group by (version) (cluster_version{_id=\"\",type=\"initial\",version!~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"no, born in 4.10 or later\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/STOR-2486","name":"VSphereStorageMountIssues","message":"vSphere customers using vSAN file volumes can't mount vSphere shared volumes and NFS volumes which server do not set NFS4ERR_ATTRNOTSUPP","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_infrastructure_provider{type=~\"VSphere|None\"})\nor\n0 * group(cluster_infrastructure_provider)\n"}}]}]},{"edges":[{"from":"4.19.10","to":"4.19.16"},{"from":"4.19.5","to":"4.19.18"},{"from":"4.19.4","to":"4.19.18"},{"from":"4.19.0","to":"4.19.17"},{"from":"4.19.2","to":"4.19.17"},{"from":"4.19.2","to":"4.19.18"},{"from":"4.19.11","to":"4.19.16"},{"from":"4.19.7","to":"4.19.18"},{"from":"4.19.10","to":"4.19.17"},{"from":"4.19.5","to":"4.19.17"},{"from":"4.19.6","to":"4.19.17"},{"from":"4.19.0","to":"4.19.18"},{"from":"4.19.12","to":"4.19.18"},{"from":"4.19.9","to":"4.19.16"},{"from":"4.19.1","to":"4.19.18"},{"from":"4.19.12","to":"4.19.17"},{"from":"4.19.11","to":"4.19.17"},{"from":"4.19.11","to":"4.19.18"},{"from":"4.19.6","to":"4.19.18"},{"from":"4.19.3","to":"4.19.18"},{"from":"4.19.4","to":"4.19.17"},{"from":"4.19.10","to":"4.19.18"},{"from":"4.19.9","to":"4.19.17"},{"from":"4.19.12","to":"4.19.16"},{"from":"4.19.1","to":"4.19.17"},{"from":"4.19.7","to":"4.19.17"},{"from":"4.19.3","to":"4.19.17"},{"from":"4.19.9","to":"4.19.18"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6483","name":"NetworkManagerOVNBridgeMapping","message":"On some clusters, the NetworkManager may delete ovs-ports on RHCOS updates, breaking Kubernetes access to those Nodes and wedging the update into the exposed release.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal|OpenStack|VSphere\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"})\n)\n* on (_id) group_left (name)\n(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"kubevirt-hyperconverged-operator[.].*\"})\n  or on (_id)\n  group by (_id, name) (kubernetes_nmstate_features_applied{_id=\"\", name=\"ovn.bridge-mappings\"} > 0)\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"} + on (_id) group_left () group by (_id) (kubernetes_nmstate_features_applied{_id=\"\"})), \"name\", \"not hyperconverged\", \"\", \"\")\n  or on (_id)\n  0 * label_replace(group by (_id) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal|OpenStack|VSphere\"}), \"name\", \"not sure about hyperconverged or ovn.bridge-mappings, but the whole platform is safe\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.19.5","to":"4.19.12"},{"from":"4.19.6","to":"4.19.12"},{"from":"4.19.4","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.0-ec.1","to":"4.18.0-ec.4"},{"from":"4.18.0-ec.0","to":"4.18.0-rc.1"},{"from":"4.18.0-ec.2","to":"4.18.0-rc.1"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.3"},{"from":"4.18.0-ec.0","to":"4.18.0-rc.0"},{"from":"4.18.0-ec.1","to":"4.18.0-ec.3"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.4"},{"from":"4.18.0-ec.2","to":"4.18.0-ec.4"},{"from":"4.18.0-ec.2","to":"4.18.0-rc.0"},{"from":"4.18.0-ec.1","to":"4.18.0-rc.0"},{"from":"4.18.0-ec.2","to":"4.18.0-ec.3"},{"from":"4.18.0-ec.1","to":"4.18.0-rc.1"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPBUGS-42671","name":"CMOSuddenStrictConfigValidation","message":"The Cluster Monitoring Operator (CMO) now validates the content of its ConfigMaps more strictly.\n\nThis may result in the operator being marked as `Degraded` and `Unavailable` while updating to a version with strict validation if any of the ConfigMaps contain invalid configurations.\n\nThe error messages should be clear enough to help identify and correct any eventual issues.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.22","to":"4.19.9"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.0-ec.0","to":"4.19.0-ec.2"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.1"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.3"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.19","to":"4.19.12"},{"from":"4.18.21","to":"4.19.12"},{"from":"4.18.20","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3671","name":"NVMeSymlinkRegeneration","message":"Clusters updating from 4.18.x may experience NVMe symlink regeneration issues when upgrading to this version.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (name) (csv_succeeded{_id=\"\", name=~\"local-storage-operator[.].*\"})\n  or on (_id)\n  0 * group by (_id) (csv_count{_id=\"\"})\n) * on (_id) group_left (type)\n(\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or on (_id)\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.0-ec.4","to":"4.18.1"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1481","name":"MachineConfigServerCARotation","message":"4.18.0-ec.4 adjusted machine-config server CA management.  The change was reverted in 4.18.0-rc.0, but clusters running 4.18.0-ec.4 need manual steps to be able to scale new Machines.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.0-rc.5","to":"4.18.1"},{"from":"4.18.0-rc.9","to":"4.18.1"},{"from":"4.18.3","to":"4.18.5"},{"from":"4.18.1","to":"4.18.2"},{"from":"4.18.0-rc.6","to":"4.18.1"},{"from":"4.18.4","to":"4.18.5"},{"from":"4.18.0-rc.4","to":"4.18.1"},{"from":"4.18.1","to":"4.18.5"},{"from":"4.18.2","to":"4.18.4"},{"from":"4.18.0-rc.7","to":"4.18.1"},{"from":"4.18.2","to":"4.18.3"},{"from":"4.18.2","to":"4.18.5"},{"from":"4.18.1","to":"4.18.4"},{"from":"4.18.1","to":"4.18.3"},{"from":"4.18.0-rc.8","to":"4.18.1"},{"from":"4.18.3","to":"4.18.4"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.19.0","to":"4.19.12"},{"from":"4.19.1","to":"4.19.12"},{"from":"4.19.2","to":"4.19.12"},{"from":"4.19.3","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1705","name":"HyperShiftClusterVersionOperatorMetrics","message":"Hosted/HyperShift clusters in exposed releases will fail to scrape cluster-version operator metrics.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]}]}