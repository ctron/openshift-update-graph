{"version":1,"nodes":[{"version":"4.18.7","payload":"quay.io/openshift-release-dev/ocp-release@sha256:91037938dc2ebc2732e7baa6eb4192fa4376abab19f0f545848a87ab7c91931d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:91037938dc2ebc2732e7baa6eb4192fa4376abab19f0f545848a87ab7c91931d","url":"https://access.redhat.com/errata/RHBA-2025:3293"}},{"version":"4.19.0-rc.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:6fbf12e60c001586c93f9b69d7d24c899503ef401ead5988f82f45cd2d10cba9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:6fbf12e60c001586c93f9b69d7d24c899503ef401ead5988f82f45cd2d10cba9","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.19.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0b44c4b526b4743e744cb989c6fc768fdfd9ac9abffc8f43a014bb90b7bf522d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0b44c4b526b4743e744cb989c6fc768fdfd9ac9abffc8f43a014bb90b7bf522d","url":"https://access.redhat.com/errata/RHBA-2025:10290"}},{"version":"4.18.8","payload":"quay.io/openshift-release-dev/ocp-release@sha256:509888097ba7d3b4eeb5aac0586acff2ec13fff07004ac692e0dcf5cf4fe2690","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:509888097ba7d3b4eeb5aac0586acff2ec13fff07004ac692e0dcf5cf4fe2690","url":"https://access.redhat.com/errata/RHSA-2025:3577"}},{"version":"4.18.0-ec.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d2d34aafe0adda79953dd928b946ecbda34673180ee9a80d2ee37c123a0f510c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](0.*|[1-4])|18[.]0-ec[.][0-2])[+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d2d34aafe0adda79953dd928b946ecbda34673180ee9a80d2ee37c123a0f510c"}},{"version":"4.18.14","payload":"quay.io/openshift-release-dev/ocp-release@sha256:78c0475ba249e03b0ed5b3d3cca619020a2996fb75efb9e7b5a2d5972fbdac7c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:78c0475ba249e03b0ed5b3d3cca619020a2996fb75efb9e7b5a2d5972fbdac7c","url":"https://access.redhat.com/errata/RHSA-2025:7863"}},{"version":"4.18.0-rc.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:bc8f69a3e79214394c573e331cfd6105a540d79c7f17ae4549fe4dcffd1c8190","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:bc8f69a3e79214394c573e331cfd6105a540d79c7f17ae4549fe4dcffd1c8190","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.24","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2db093f063ad5310fa4e5ed2d2eda4bad5215c47092b72d1cfafbcfdbf1f4dd2","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.].*|18[.](1?[0-9]|2[0-1]))[+].*$|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|17[.](([0-9]|[1-2][0-9]|3[0-7])))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2db093f063ad5310fa4e5ed2d2eda4bad5215c47092b72d1cfafbcfdbf1f4dd2","url":"https://access.redhat.com/errata/RHBA-2025:15714"}},{"version":"4.18.0-rc.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0644a286c7480945553904ef8775bb75ca950287ea1c9ad6cc8ff56890aebc05","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0644a286c7480945553904ef8775bb75ca950287ea1c9ad6cc8ff56890aebc05","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.9","payload":"quay.io/openshift-release-dev/ocp-release@sha256:720f89718effd16de7d77e5533c9608f1845295a2e00dfff543d0cf9aa09b2a0","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:720f89718effd16de7d77e5533c9608f1845295a2e00dfff543d0cf9aa09b2a0","url":"https://access.redhat.com/errata/RHSA-2025:3775"}},{"version":"4.19.0-rc.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:6e7c9d6ff30e66f77a84862dba12bee23305139abe4b2bb29f9c796bdf852b7d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:6e7c9d6ff30e66f77a84862dba12bee23305139abe4b2bb29f9c796bdf852b7d","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.19.10","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2f9145136fb387d43c7fff55b30a036c14eb96b0992c292274b6f543c6c33857","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2f9145136fb387d43c7fff55b30a036c14eb96b0992c292274b6f543c6c33857","url":"https://access.redhat.com/errata/RHBA-2025:14823"}},{"version":"4.18.15","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0ebcecebc52a63285669ed74f0e591865b702de34c0a488cbba02dfb53d71cbe","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0ebcecebc52a63285669ed74f0e591865b702de34c0a488cbba02dfb53d71cbe","url":"https://access.redhat.com/errata/RHBA-2025:8104"}},{"version":"4.19.0-ec.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2736d8dcfc57058fb77f1c34821ccfd1d07fdb505045e77493c59f06bf70e938","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2736d8dcfc57058fb77f1c34821ccfd1d07fdb505045e77493c59f06bf70e938"}},{"version":"4.18.0-ec.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8e097e389656b8b6e362c596b08f929d9271b4f841570f310b13b497a4f2b7d9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.]18[.]0-ec[.][0-2][+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8e097e389656b8b6e362c596b08f929d9271b4f841570f310b13b497a4f2b7d9"}},{"version":"4.18.11","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b3c76706606940d84964095aaab1a8ed4eca0d1bd6833b4eb718115842ef6850","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|.*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:b3c76706606940d84964095aaab1a8ed4eca0d1bd6833b4eb718115842ef6850","url":"https://access.redhat.com/errata/RHSA-2025:4211"}},{"version":"4.19.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:bc79be35e8b8a3719a3e16c91b64e5945c6c4ff1a9c9d0816339f14e2b004385","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:bc79be35e8b8a3719a3e16c91b64e5945c6c4ff1a9c9d0816339f14e2b004385","url":"https://access.redhat.com/errata/RHSA-2025:11363"}},{"version":"4.19.9","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b6f3a6e7cab0bb6e2590f6e6612a3edec75e3b28d32a4e55325bdeeb7d836662","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:b6f3a6e7cab0bb6e2590f6e6612a3edec75e3b28d32a4e55325bdeeb7d836662","url":"https://access.redhat.com/errata/RHSA-2025:13848"}},{"version":"4.19.11","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d28dff1fd2bbbf7e923d24da21c921c53b61089690fbbe9d4b03c847487c2b5f","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d28dff1fd2bbbf7e923d24da21c921c53b61089690fbbe9d4b03c847487c2b5f","url":"https://access.redhat.com/errata/RHBA-2025:15293"}},{"version":"4.18.6","payload":"quay.io/openshift-release-dev/ocp-release@sha256:61fdad894f035a8b192647c224faf565279518255bdbf60a91db4ee0479adaa6","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:61fdad894f035a8b192647c224faf565279518255bdbf60a91db4ee0479adaa6","url":"https://access.redhat.com/errata/RHSA-2025:3066"}},{"version":"4.19.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8153a8c010b292c0c4ca7d8b4ca13ebeb634d449982c66568764511c736281b8","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8153a8c010b292c0c4ca7d8b4ca13ebeb634d449982c66568764511c736281b8","url":"https://access.redhat.com/errata/RHSA-2025:10771"}},{"version":"4.18.0-rc.9","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d59d8a478a51fd9aaf5ddb9a61bb082e38bbd3777d899f9804f256c070e302ae","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d59d8a478a51fd9aaf5ddb9a61bb082e38bbd3777d899f9804f256c070e302ae","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.0-ec.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:aa3e0a3a94babd90535f8298ab274b51a9bce6045dda8c3c8cd742bc59f0e2d9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.](18[.]0-(ec[.].*|rc[.][0-3])|19[.]0-ec[.]0)|.*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:aa3e0a3a94babd90535f8298ab274b51a9bce6045dda8c3c8cd742bc59f0e2d9"}},{"version":"4.18.26","payload":"quay.io/openshift-release-dev/ocp-release@sha256:dcd5fce7701d1e568ffb1065800a4aa34c911910400209224e702b951412171d","metadata":{"io.openshift.upgrades.graph.release.channels":"candidate-4.18,fast-4.18,candidate-4.19,fast-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:dcd5fce7701d1e568ffb1065800a4aa34c911910400209224e702b951412171d","url":"https://access.redhat.com/errata/RHSA-2025:17657"}},{"version":"4.18.19","payload":"quay.io/openshift-release-dev/ocp-release@sha256:e6d80b9ab85b17b47e90cb8de1b9ad0e3fe457780148629d329d532ef902d222","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:e6d80b9ab85b17b47e90cb8de1b9ad0e3fe457780148629d329d532ef902d222","url":"https://access.redhat.com/errata/RHSA-2025:9725"}},{"version":"4.19.12","payload":"quay.io/openshift-release-dev/ocp-release@sha256:f0ca7c0e9ede6440119f3fd90abdd87e77cf99b7e68d6c1f95ec1872c62cbb17","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|.*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:f0ca7c0e9ede6440119f3fd90abdd87e77cf99b7e68d6c1f95ec1872c62cbb17","url":"https://access.redhat.com/errata/RHBA-2025:15694"}},{"version":"4.19.6","payload":"quay.io/openshift-release-dev/ocp-release@sha256:02ec914b5380b9e4e048b830c9521e8d11f7f613d4ff3977147107770288a595","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:02ec914b5380b9e4e048b830c9521e8d11f7f613d4ff3977147107770288a595","url":"https://access.redhat.com/errata/RHSA-2025:11673"}},{"version":"4.19.13","payload":"quay.io/openshift-release-dev/ocp-release@sha256:b221339d28377e7654ecfa76debf7cd11eccc4e45516cca393df6a5ca4dbc736","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|.*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:b221339d28377e7654ecfa76debf7cd11eccc4e45516cca393df6a5ca4dbc736","url":"https://access.redhat.com/errata/RHBA-2025:16148"}},{"version":"4.18.0-rc.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:668c92b06279cb5c7a2a692860b297eeb9013af10d49d2095f2c3fe9ad02baaa","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:668c92b06279cb5c7a2a692860b297eeb9013af10d49d2095f2c3fe9ad02baaa","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.0-ec.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:573a86d57acab6dfb90799f568421e80a41f85aaef1e94a16e13af13339524c1","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.](18[.]0-(ec[.].*|rc[.][0-3])|19[.]0-ec[.]0)|.*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:573a86d57acab6dfb90799f568421e80a41f85aaef1e94a16e13af13339524c1"}},{"version":"4.18.0-rc.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:054e75395dd0879e8c29cd059cf6b782742123177a303910bf78f28880431d1c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.]18[.]0-ec[.][0-2][+].*$|4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:054e75395dd0879e8c29cd059cf6b782742123177a303910bf78f28880431d1c","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.21","payload":"quay.io/openshift-release-dev/ocp-release@sha256:9d1b107adad76f023493b8c2b74902639f66273cc120e255454ad447a9ef27d9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:9d1b107adad76f023493b8c2b74902639f66273cc120e255454ad447a9ef27d9","url":"https://access.redhat.com/errata/RHSA-2025:11677"}},{"version":"4.18.0-rc.6","payload":"quay.io/openshift-release-dev/ocp-release@sha256:1d261c178ac128e85455f370a78f3fea4492cd5c0367888933fe3a5b48c43c84","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:1d261c178ac128e85455f370a78f3fea4492cd5c0367888933fe3a5b48c43c84","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.7","payload":"quay.io/openshift-release-dev/ocp-release@sha256:bd4cd954feebfe3a6b2847c20271e8f3ba21e99ac1e234db6ce4cf2207f8955a","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:bd4cd954feebfe3a6b2847c20271e8f3ba21e99ac1e234db6ce4cf2207f8955a","url":"https://access.redhat.com/errata/RHSA-2025:12341"}},{"version":"4.19.0-ec.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:3c7decd8e09329d5206a96bcc19838d25bdc3af9c9565f249aa91494c7beb7db","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.](18[.]0-(ec[.].*|rc[.][0-3])|19[.]0-ec[.]0)|.*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:3c7decd8e09329d5206a96bcc19838d25bdc3af9c9565f249aa91494c7beb7db"}},{"version":"4.19.0-ec.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:1e9baecce90105b4c0aa695dadc2fac7e4b9fd54e0d2ede90e143e57df8e424a","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:1e9baecce90105b4c0aa695dadc2fac7e4b9fd54e0d2ede90e143e57df8e424a"}},{"version":"4.18.0-rc.7","payload":"quay.io/openshift-release-dev/ocp-release@sha256:2175ebf62c8565098f1628c588c86c99e4418fc7b97b05ee5c803096b03aea90","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:2175ebf62c8565098f1628c588c86c99e4418fc7b97b05ee5c803096b03aea90","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.0-rc.10","payload":"quay.io/openshift-release-dev/ocp-release@sha256:35f285f833999f8d91300428c7401eae71759901cc821c33e0a7312d5e6444d7","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:35f285f833999f8d91300428c7401eae71759901cc821c33e0a7312d5e6444d7","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.14","payload":"quay.io/openshift-release-dev/ocp-release@sha256:f8e21e76897b3f9b8a76a07b5a9426ba8def9b2e56b18d8b40ad65931b8bbf78","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:f8e21e76897b3f9b8a76a07b5a9426ba8def9b2e56b18d8b40ad65931b8bbf78","url":"https://access.redhat.com/errata/RHBA-2025:16693"}},{"version":"4.19.15","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d96bf58288bfe00d347707ba0b9fa5455ee0d506ae4dfe417518473197ee16ab","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d96bf58288bfe00d347707ba0b9fa5455ee0d506ae4dfe417518473197ee16ab","url":"https://access.redhat.com/errata/RHBA-2025:17237"}},{"version":"4.18.12","payload":"quay.io/openshift-release-dev/ocp-release@sha256:31e8978d1f7a24c3e70dcc12c93dd5e73311b78e528f73beb020ddbe3270e07d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|4[.]17[.].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:31e8978d1f7a24c3e70dcc12c93dd5e73311b78e528f73beb020ddbe3270e07d","url":"https://access.redhat.com/errata/RHSA-2025:4427"}},{"version":"4.19.0-ec.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:fde51d1c35425759c83ea0895d0d4fc0f88f6a49a0d080207f15a7bbe3e9982c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:fde51d1c35425759c83ea0895d0d4fc0f88f6a49a0d080207f15a7bbe3e9982c"}},{"version":"4.18.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:46f9db00dac167897378825ea5f3cce0867743ac90498bbb61b0816daedd0d00","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:46f9db00dac167897378825ea5f3cce0867743ac90498bbb61b0816daedd0d00","url":"https://access.redhat.com/errata/RHBA-2025:1904"}},{"version":"4.18.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:d9c985464c0315160971b3e79f5fbec628d403a572f7a6d893c04627c066c0bb","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|4[.]18[.]0-ec[.]4[+].*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:d9c985464c0315160971b3e79f5fbec628d403a572f7a6d893c04627c066c0bb","url":"https://access.redhat.com/errata/RHSA-2024:6122"}},{"version":"4.19.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:3482dbdce3a6fb2239684d217bba6fc87453eff3bdb72f5237be4beb22a2160b","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|^4[.]18[.](1[01]|[0-9])[+].*$|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:3482dbdce3a6fb2239684d217bba6fc87453eff3bdb72f5237be4beb22a2160b","url":"https://access.redhat.com/errata/RHSA-2024:11038"}},{"version":"4.18.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:fdcb3da3a1086d664df31a1fa2a629c77780f844d458af956928cca297da343c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:fdcb3da3a1086d664df31a1fa2a629c77780f844d458af956928cca297da343c","url":"https://access.redhat.com/errata/RHBA-2025:2229"}},{"version":"4.18.0-rc.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5274f17dc4375df73cdeccf43aa4fc268230f1ca2867738f56807d026f2aa8ba","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.]18[.]0-ec[.][0-2][+].*$|4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:5274f17dc4375df73cdeccf43aa4fc268230f1ca2867738f56807d026f2aa8ba","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.17","payload":"quay.io/openshift-release-dev/ocp-release@sha256:9d24a8cdd67b8f18c99547d5910e4863e7aab5bd888e26670a00dbda0a9d4687","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:9d24a8cdd67b8f18c99547d5910e4863e7aab5bd888e26670a00dbda0a9d4687","url":"https://access.redhat.com/errata/RHSA-2025:8560"}},{"version":"4.18.0-ec.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:e87292db8d5790f7059d90a449feab27aaa3299ac22f05f12b9bc9609468f67d","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:e87292db8d5790f7059d90a449feab27aaa3299ac22f05f12b9bc9609468f67d"}},{"version":"4.19.0-rc.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:86ef3b06739c0fbcc2bd36c85e2685d19b38f7c776601a8389759648abc8e32b","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:86ef3b06739c0fbcc2bd36c85e2685d19b38f7c776601a8389759648abc8e32b","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.25","payload":"quay.io/openshift-release-dev/ocp-release@sha256:ba6f0f2eca65cd386a5109ddbbdb3bab9bb9801e32de56ef34f80e634a7787be","metadata":{"io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:ba6f0f2eca65cd386a5109ddbbdb3bab9bb9801e32de56ef34f80e634a7787be","url":"https://access.redhat.com/errata/RHBA-2025:16732"}},{"version":"4.18.0-ec.0","payload":"quay.io/openshift-release-dev/ocp-release@sha256:e930176c384d1c819f6259c403cb9a4fe419eebb1da80a9ae0a0e8afbd74d964","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:e930176c384d1c819f6259c403cb9a4fe419eebb1da80a9ae0a0e8afbd74d964"}},{"version":"4.19.16","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8f57c0a381695f49c15e4b337f0259a02de2cfa10be3882a6fb795c34217d212","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8f57c0a381695f49c15e4b337f0259a02de2cfa10be3882a6fb795c34217d212","url":"https://access.redhat.com/errata/RHBA-2025:17662"}},{"version":"4.18.16","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0dac222584991f89a123d85e8c3055f0056e5876fc209b8d4bea7a59e7504d59","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0dac222584991f89a123d85e8c3055f0056e5876fc209b8d4bea7a59e7504d59","url":"https://access.redhat.com/errata/RHSA-2025:8284"}},{"version":"4.18.0-rc.8","payload":"quay.io/openshift-release-dev/ocp-release@sha256:f0de3be10be2f5fc1a5b1c208bcfe5d3a71a70989cacbca57ebf7c5fe6e14b09","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:f0de3be10be2f5fc1a5b1c208bcfe5d3a71a70989cacbca57ebf7c5fe6e14b09","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.18.0-rc.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:23e31abd998aa80ee11344e6ad910d8283d4f2f973c79e9d7fecbd355be459ab","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.]0-ec[.]4[+].*|.*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:23e31abd998aa80ee11344e6ad910d8283d4f2f973c79e9d7fecbd355be459ab","url":"https://access.redhat.com/errata/RHEA-2024:6122"}},{"version":"4.19.0-rc.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5d3a4b9203759cf8ae97546f35128decca063e83181c2ba4407177db252e919c","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:5d3a4b9203759cf8ae97546f35128decca063e83181c2ba4407177db252e919c","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.19.17","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5c01281c55d75a1569440f91d2708125f14533c675b96d7be67b7a1badd759e5","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19","io.openshift.upgrades.graph.release.manifestref":"sha256:5c01281c55d75a1569440f91d2708125f14533c675b96d7be67b7a1badd759e5","url":"https://access.redhat.com/errata/RHSA-2025:18233"}},{"version":"4.18.22","payload":"quay.io/openshift-release-dev/ocp-release@sha256:16078b671c7f5490a2136f2cd9a694d48bb38af1280ef9e2ae9ce28af075cca5","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|^4[.](17[.].*|18[.](1?[0-9]|2[0-1]))[+].*$|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|17[.](([0-9]|[1-2][0-9]|3[0-7])))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:16078b671c7f5490a2136f2cd9a694d48bb38af1280ef9e2ae9ce28af075cca5","url":"https://access.redhat.com/errata/RHSA-2025:13325"}},{"version":"4.18.13","payload":"quay.io/openshift-release-dev/ocp-release@sha256:a93c65b0f9de1d2e29641fbeebc07178733db1cacc7bde178033d7b9183540bc","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](17[.](2[0-8]|[1]?[0-9])|18[.](1[01]|[0-9]))[+].*$|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:a93c65b0f9de1d2e29641fbeebc07178733db1cacc7bde178033d7b9183540bc","url":"https://access.redhat.com/errata/RHSA-2025:4712"}},{"version":"4.18.5","payload":"quay.io/openshift-release-dev/ocp-release@sha256:93879f84b3165c5b5bd1fdf4563a11155dc61ea35cd93e67dc61c2b66e11c8bb","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:93879f84b3165c5b5bd1fdf4563a11155dc61ea35cd93e67dc61c2b66e11c8bb","url":"https://access.redhat.com/errata/RHSA-2025:2705"}},{"version":"4.18.23","payload":"quay.io/openshift-release-dev/ocp-release@sha256:0bf2e8c1edf16de717c330b94d85f6d463c7208956b0a545cbb3fcf715e14c38","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|^4[.](17[.].*|18[.](1?[0-9]|2[0-1]))[+].*$|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|17[.](([0-9]|[1-2][0-9]|3[0-7])))[+].*$","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:0bf2e8c1edf16de717c330b94d85f6d463c7208956b0a545cbb3fcf715e14c38","url":"https://access.redhat.com/errata/RHSA-2025:14820"}},{"version":"4.19.1","payload":"quay.io/openshift-release-dev/ocp-release@sha256:4d7f10e383deb0c5402f871bf66ebdcad6bb670cb3cf1668bfec5166c56f3196","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:4d7f10e383deb0c5402f871bf66ebdcad6bb670cb3cf1668bfec5166c56f3196","url":"https://access.redhat.com/errata/RHSA-2025:9278"}},{"version":"4.19.8","payload":"quay.io/openshift-release-dev/ocp-release@sha256:456c17bbf692804c746ee5651a222670c91fdcc36993731d4ff8c92bbb3ed4b4","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"^4[.](18[.].*|19[.][0-6])[+].*$|^4[.](18[.](1?[0-9]|2[0-1])|19[.][0-3])[+].*$|4[.]18[.].*|4[.]18[.].*|^4[.](18[.]([0-9]|1[0-9]|2[0-1])|19[.][0-7])[+].*$|4[.]18[.].*|4[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19","io.openshift.upgrades.graph.release.manifestref":"sha256:456c17bbf692804c746ee5651a222670c91fdcc36993731d4ff8c92bbb3ed4b4","url":"https://access.redhat.com/errata/RHSA-2025:13319"}},{"version":"4.19.0-rc.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:596f4d804654419241c1894fb6d54066718f254aab58dfa8892bb26390ba3df9","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:596f4d804654419241c1894fb6d54066718f254aab58dfa8892bb26390ba3df9","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.19.0-rc.3","payload":"quay.io/openshift-release-dev/ocp-release@sha256:8970801dee5031571f971bdf922d351f884065ceb3e441c173c8350b3956a229","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:8970801dee5031571f971bdf922d351f884065ceb3e441c173c8350b3956a229","url":"https://access.redhat.com/errata/RHEA-2024:11038"}},{"version":"4.18.18","payload":"quay.io/openshift-release-dev/ocp-release@sha256:eca2e3f7de2bd92b18f69547c8f0ad842fdb83f0821f76b8692f2716a86b0bde","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:eca2e3f7de2bd92b18f69547c8f0ad842fdb83f0821f76b8692f2716a86b0bde","url":"https://access.redhat.com/errata/RHSA-2025:9269"}},{"version":"4.19.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:1293f5ccad2a2776241344faecaf7320f60ee91882df4e24b309f3a7cefc04be","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4.18.*|4.18[.].*|4.18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*|4[.]18[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:1293f5ccad2a2776241344faecaf7320f60ee91882df4e24b309f3a7cefc04be","url":"https://access.redhat.com/errata/RHSA-2025:9750"}},{"version":"4.18.4","payload":"quay.io/openshift-release-dev/ocp-release@sha256:61dffd292f6689a3381dd05f7845dcd5d27c099fce2f460aa03d760d535f81e6","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*|4[.]17[.].*|4[.](17[.](1[01]|0-.*|[0-9])|18.0-(ec[.].*|rc[.][0-3]))|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:61dffd292f6689a3381dd05f7845dcd5d27c099fce2f460aa03d760d535f81e6","url":"https://access.redhat.com/errata/RHSA-2025:2449"}},{"version":"4.18.0-ec.2","payload":"quay.io/openshift-release-dev/ocp-release@sha256:a3233d18821af30610bc16d4a3d0f45a5f6bcfbb50eda139b8b82b824a78559f","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":".*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,candidate-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:a3233d18821af30610bc16d4a3d0f45a5f6bcfbb50eda139b8b82b824a78559f"}},{"version":"4.18.20","payload":"quay.io/openshift-release-dev/ocp-release@sha256:5e06105a6ba80d04eb5d8d3f9a672fb743ce4710876d99a375c2d9f7b7eaa783","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:5e06105a6ba80d04eb5d8d3f9a672fb743ce4710876d99a375c2d9f7b7eaa783","url":"https://access.redhat.com/errata/RHSA-2025:10767"}},{"version":"4.18.10","payload":"quay.io/openshift-release-dev/ocp-release@sha256:be8bcea2ab176321a4e1e54caab4709f9024bc437e52ca5bc088e729367cd0cf","metadata":{"io.openshift.upgrades.graph.previous.remove_regex":"4[.]17[.].*|.*|^4[.](17[.]([0-9]|1[0-6]))[+].*$|4[.]17[.].*|^4[.](17[.]([1]?[0-9]|2[0-1])|18[.][0-5])[+].*$|4[.]17[.].*","io.openshift.upgrades.graph.release.channels":"candidate-4.18,eus-4.18,fast-4.18,stable-4.18,candidate-4.19,fast-4.19,stable-4.19,candidate-4.20","io.openshift.upgrades.graph.release.manifestref":"sha256:be8bcea2ab176321a4e1e54caab4709f9024bc437e52ca5bc088e729367cd0cf","url":"https://access.redhat.com/errata/RHSA-2025:4019"}}],"edges":[[59,23],[71,24],[11,57],[47,50],[5,12],[71,23],[1,44],[7,23],[40,23],[3,23],[5,47],[47,66],[53,31],[45,50],[39,57],[0,24],[38,57],[27,57],[25,57],[18,57],[64,44],[24,31],[9,66],[45,31],[68,31],[58,23],[43,70],[53,50],[31,50],[60,24],[9,50],[40,66],[49,44],[42,66],[42,31],[58,7],[40,50],[39,52],[44,52],[40,12],[43,23],[19,24],[20,52],[66,24],[12,47],[34,44],[68,24],[59,50],[5,50],[19,31],[2,57],[9,23],[0,9],[16,26],[13,44],[42,23],[19,50],[50,23],[71,70],[59,24],[35,44],[71,50],[5,23],[65,44],[3,24],[12,50],[58,50],[17,52],[66,70],[66,31],[70,50],[67,57],[26,52],[5,53],[44,67],[71,31],[45,66],[17,57],[0,66],[45,23],[53,70],[68,23],[52,57],[42,70],[60,50],[68,66],[16,57],[62,52],[40,70],[27,52],[10,44],[43,66],[60,31],[20,57],[12,31],[47,23],[47,31],[17,11],[19,66],[0,23],[59,12],[18,52],[62,2],[67,2],[44,2],[15,50],[7,50],[66,50],[43,31],[3,66],[3,70],[61,23],[11,52],[29,44],[40,59],[24,23],[47,24],[20,16],[40,47],[63,17],[68,70],[40,5],[33,52],[59,5],[40,24],[47,70],[24,70],[19,0],[56,44],[2,52],[15,66],[20,26],[33,57],[45,70],[62,57],[53,66],[42,24],[26,57],[15,24],[11,18],[5,66],[16,52],[19,3],[53,23],[63,52],[68,50],[12,23],[9,24],[44,57],[5,31],[9,31],[3,9],[31,23],[59,66],[12,24],[63,11],[19,23],[60,66],[70,23],[66,23],[0,31],[43,50],[24,50],[71,66],[59,47],[59,53],[12,53],[9,70],[41,44],[59,70],[0,70],[0,50],[61,7],[22,44],[5,70],[19,9],[15,31],[3,50],[17,18],[38,52],[5,24],[19,70],[60,23],[15,23],[42,50],[70,31],[59,31],[67,52],[40,31],[44,62],[53,24],[63,18],[40,53],[12,66],[53,47],[43,24],[60,70],[12,70],[15,70],[62,67],[0,3],[25,52],[45,24],[61,50],[63,57],[3,31]],"conditionalEdges":[{"edges":[{"from":"4.18.21","to":"4.19.8"},{"from":"4.18.20","to":"4.19.8"},{"from":"4.18.19","to":"4.19.8"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3503","name":"RHEL96Kernel331Panic","message":"After OCP 4.19.8 was tagged Red Hat has become aware of a kernel regression in kernel-5.14.0-570.33.1.el9_6 and as a result 4.19.8 will not ship or be promoted beyond candidate channels. Updates to this version are not recommended. ","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.19","to":"4.19.3"},{"from":"4.18.16","to":"4.19.3"},{"from":"4.18.18","to":"4.19.3"},{"from":"4.18.17","to":"4.19.3"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1109","name":"HCPMetallbCNOCannotDeployFRRK8S","message":"On Hosted Control Plane (HCP/HyperShift) clusters with installed MetalLB operator, Cluster Network Operator fails to\ndeploy a critical component FRR-k8s when updated. MetalLB will stop working properly and stop advertising services,\nmaking them potentially unreachable from outside the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\ngroup by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\nand on (_id) (\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n)\nor on (_id) (\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1110","name":"HCPServiceHealthCheckDisruption","message":"When Hosted Control Plane (HCP/HyperShift) clusters running on AWS update a node pool, the Services of type\nLoadBalancer may experience temporary availability disruption because health checks are not set up properly to monitor\nNode readiness state.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\n  or\n  0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\n* on (_id) group_left (type) (\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3357","name":"OldBootImagesComposeFSvsGrubProbe","message":"Upgrade to 4.19 will fail due to a boot image incompatibility issue if a cluster was born in 4.2 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  label_replace(group by (version) (cluster_version{_id=\"\",type=\"initial\",version=~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"yes, so possibly actually born in 4.2 or earlier\", \"\", \"\")\n  or\n  label_replace(0 * group by (version) (cluster_version{_id=\"\",type=\"initial\",version!~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"no, born in 4.10 or later\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.18.23","to":"4.19.14"},{"from":"4.18.25","to":"4.19.14"},{"from":"4.18.22","to":"4.19.15"},{"from":"4.18.25","to":"4.19.15"},{"from":"4.18.23","to":"4.19.15"},{"from":"4.18.20","to":"4.19.14"},{"from":"4.18.24","to":"4.19.15"},{"from":"4.18.24","to":"4.19.14"},{"from":"4.18.19","to":"4.19.14"},{"from":"4.18.22","to":"4.19.14"},{"from":"4.18.21","to":"4.19.14"},{"from":"4.18.19","to":"4.19.15"},{"from":"4.18.20","to":"4.19.15"},{"from":"4.18.21","to":"4.19.15"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.2","to":"4.19.12"},{"from":"4.19.2","to":"4.19.13"},{"from":"4.19.0","to":"4.19.13"},{"from":"4.19.0","to":"4.19.12"},{"from":"4.19.1","to":"4.19.12"},{"from":"4.19.3","to":"4.19.12"},{"from":"4.19.1","to":"4.19.13"},{"from":"4.19.3","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.7","to":"4.19.8"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3503","name":"RHEL96Kernel331Panic","message":"After OCP 4.19.8 was tagged Red Hat has become aware of a kernel regression in kernel-5.14.0-570.33.1.el9_6 and as a result 4.19.8 will not ship or be promoted beyond candidate channels. Updates to this version are not recommended. ","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.19.4","to":"4.19.9"},{"from":"4.19.5","to":"4.19.10"},{"from":"4.19.4","to":"4.19.11"},{"from":"4.19.6","to":"4.19.10"},{"from":"4.19.5","to":"4.19.11"},{"from":"4.19.6","to":"4.19.9"},{"from":"4.19.5","to":"4.19.9"},{"from":"4.19.6","to":"4.19.11"},{"from":"4.19.4","to":"4.19.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.22","to":"4.19.9"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.0-ec.4","to":"4.18.1"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1481","name":"MachineConfigServerCARotation","message":"4.18.0-ec.4 adjusted machine-config server CA management.  The change was reverted in 4.18.0-rc.0, but clusters running 4.18.0-ec.4 need manual steps to be able to scale new Machines.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.15","to":"4.18.24"},{"from":"4.18.2","to":"4.18.24"},{"from":"4.18.16","to":"4.18.24"},{"from":"4.18.8","to":"4.18.24"},{"from":"4.18.7","to":"4.18.24"},{"from":"4.18.6","to":"4.18.24"},{"from":"4.18.19","to":"4.18.24"},{"from":"4.18.13","to":"4.18.24"},{"from":"4.18.18","to":"4.18.24"},{"from":"4.18.3","to":"4.18.24"},{"from":"4.18.11","to":"4.18.24"},{"from":"4.18.21","to":"4.18.24"},{"from":"4.18.9","to":"4.18.24"},{"from":"4.18.4","to":"4.18.24"},{"from":"4.18.14","to":"4.18.24"},{"from":"4.18.17","to":"4.18.24"},{"from":"4.18.1","to":"4.18.24"},{"from":"4.18.10","to":"4.18.24"},{"from":"4.18.12","to":"4.18.24"},{"from":"4.18.5","to":"4.18.24"},{"from":"4.18.20","to":"4.18.24"}],"risks":[{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.12","to":"4.19.13"},{"from":"4.19.11","to":"4.19.12"},{"from":"4.19.9","to":"4.19.12"},{"from":"4.19.11","to":"4.19.13"},{"from":"4.19.8","to":"4.19.12"},{"from":"4.19.8","to":"4.19.13"},{"from":"4.19.9","to":"4.19.13"},{"from":"4.19.10","to":"4.19.13"},{"from":"4.19.10","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.6","to":"4.19.13"},{"from":"4.19.5","to":"4.19.13"},{"from":"4.19.4","to":"4.19.13"},{"from":"4.19.5","to":"4.19.12"},{"from":"4.19.4","to":"4.19.12"},{"from":"4.19.6","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.19","to":"4.19.4"},{"from":"4.18.20","to":"4.19.4"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1110","name":"HCPServiceHealthCheckDisruption","message":"When Hosted Control Plane (HCP/HyperShift) clusters running on AWS update a node pool, the Services of type\nLoadBalancer may experience temporary availability disruption because health checks are not set up properly to monitor\nNode readiness state.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\n  or\n  0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\n* on (_id) group_left (type) (\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3357","name":"OldBootImagesComposeFSvsGrubProbe","message":"Upgrade to 4.19 will fail due to a boot image incompatibility issue if a cluster was born in 4.2 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  label_replace(group by (version) (cluster_version{_id=\"\",type=\"initial\",version=~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"yes, so possibly actually born in 4.2 or earlier\", \"\", \"\")\n  or\n  label_replace(0 * group by (version) (cluster_version{_id=\"\",type=\"initial\",version!~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"no, born in 4.10 or later\", \"\", \"\")\n)\n"}}]}]},{"edges":[{"from":"4.18.10","to":"4.18.22"},{"from":"4.18.18","to":"4.18.23"},{"from":"4.18.13","to":"4.18.22"},{"from":"4.18.15","to":"4.18.23"},{"from":"4.18.17","to":"4.18.23"},{"from":"4.18.20","to":"4.18.23"},{"from":"4.18.15","to":"4.18.22"},{"from":"4.18.12","to":"4.18.22"},{"from":"4.18.4","to":"4.18.22"},{"from":"4.18.4","to":"4.18.23"},{"from":"4.18.21","to":"4.18.22"},{"from":"4.18.7","to":"4.18.22"},{"from":"4.18.8","to":"4.18.22"},{"from":"4.18.9","to":"4.18.23"},{"from":"4.18.13","to":"4.18.23"},{"from":"4.18.3","to":"4.18.23"},{"from":"4.18.1","to":"4.18.23"},{"from":"4.18.2","to":"4.18.22"},{"from":"4.18.16","to":"4.18.23"},{"from":"4.18.2","to":"4.18.23"},{"from":"4.18.1","to":"4.18.22"},{"from":"4.18.19","to":"4.18.22"},{"from":"4.18.12","to":"4.18.23"},{"from":"4.18.6","to":"4.18.22"},{"from":"4.18.9","to":"4.18.22"},{"from":"4.18.7","to":"4.18.23"},{"from":"4.18.11","to":"4.18.22"},{"from":"4.18.5","to":"4.18.22"},{"from":"4.18.5","to":"4.18.23"},{"from":"4.18.19","to":"4.18.23"},{"from":"4.18.10","to":"4.18.23"},{"from":"4.18.14","to":"4.18.22"},{"from":"4.18.17","to":"4.18.22"},{"from":"4.18.18","to":"4.18.22"},{"from":"4.18.16","to":"4.18.22"},{"from":"4.18.3","to":"4.18.22"},{"from":"4.18.21","to":"4.18.23"},{"from":"4.18.11","to":"4.18.23"},{"from":"4.18.8","to":"4.18.23"},{"from":"4.18.14","to":"4.18.23"},{"from":"4.18.6","to":"4.18.23"},{"from":"4.18.20","to":"4.18.22"}],"risks":[{"url":"https://issues.redhat.com/browse/RUN-3446","name":"CrunConflictsWithNVIDIA","message":"Some crun 1.23 releases conflict with the NVIDIA GPU Operator over eBPF, causing issues with GPU workloads.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (name) (csv_succeeded{_id=\"\", name=~\"gpu-operator-certified[.].*\"})\nor on (_id)\n0 * group(csv_count{_id=\"\"})"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.3","to":"4.18.14"},{"from":"4.18.3","to":"4.18.12"},{"from":"4.18.4","to":"4.18.15"},{"from":"4.18.5","to":"4.18.13"},{"from":"4.18.1","to":"4.18.16"},{"from":"4.18.4","to":"4.18.12"},{"from":"4.18.2","to":"4.18.15"},{"from":"4.18.1","to":"4.18.14"},{"from":"4.18.2","to":"4.18.16"},{"from":"4.18.4","to":"4.18.13"},{"from":"4.18.3","to":"4.18.15"},{"from":"4.18.2","to":"4.18.14"},{"from":"4.18.2","to":"4.18.12"},{"from":"4.18.5","to":"4.18.14"},{"from":"4.18.1","to":"4.18.15"},{"from":"4.18.4","to":"4.18.16"},{"from":"4.18.5","to":"4.18.15"},{"from":"4.18.1","to":"4.18.13"},{"from":"4.18.3","to":"4.18.16"},{"from":"4.18.1","to":"4.18.12"},{"from":"4.18.4","to":"4.18.14"},{"from":"4.18.5","to":"4.18.12"},{"from":"4.18.5","to":"4.18.16"},{"from":"4.18.2","to":"4.18.13"},{"from":"4.18.3","to":"4.18.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4632","name":"ConsoleEnabledTargetDownAlert","message":"The alert TargetDown is triggered if the capability Console is enabled on the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"max(cluster_version_capability{name=\"Console\"})"}}]},{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.15","to":"4.19.0-rc.4"},{"from":"4.18.3","to":"4.19.0-ec.3"},{"from":"4.18.0-rc.6","to":"4.19.0-ec.2"},{"from":"4.18.13","to":"4.19.0-rc.3"},{"from":"4.18.2","to":"4.19.0-ec.3"},{"from":"4.18.16","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.5","to":"4.19.0-ec.1"},{"from":"4.18.14","to":"4.19.0-rc.3"},{"from":"4.18.0-rc.4","to":"4.19.0-ec.2"},{"from":"4.18.14","to":"4.19.0-rc.2"},{"from":"4.18.0-rc.9","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.8","to":"4.19.0-ec.2"},{"from":"4.18.17","to":"4.19.0-rc.5"},{"from":"4.18.1","to":"4.19.0-ec.3"},{"from":"4.18.9","to":"4.19.0-ec.5"},{"from":"4.18.0-rc.4","to":"4.19.0-ec.1"},{"from":"4.18.13","to":"4.19.0-rc.2"},{"from":"4.18.8","to":"4.19.0-ec.5"},{"from":"4.18.13","to":"4.19.0-rc.4"},{"from":"4.18.7","to":"4.19.0-ec.5"},{"from":"4.18.6","to":"4.19.0-ec.4"},{"from":"4.18.0-rc.1","to":"4.19.0-ec.0"},{"from":"4.18.16","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.5","to":"4.19.0-ec.2"},{"from":"4.18.13","to":"4.19.0-rc.0"},{"from":"4.18.6","to":"4.19.0-ec.5"},{"from":"4.18.14","to":"4.19.0-rc.4"},{"from":"4.18.10","to":"4.19.0-ec.5"},{"from":"4.18.7","to":"4.19.0-ec.4"},{"from":"4.18.13","to":"4.19.0-rc.1"},{"from":"4.18.0-rc.7","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.0","to":"4.19.0-ec.0"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/STOR-2486","name":"VSphereStorageMountIssues","message":"vSphere customers using vSAN file volumes can't mount vSphere shared volumes and NFS volumes which server do not set NFS4ERR_ATTRNOTSUPP","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_infrastructure_provider{type=~\"VSphere|None\"})\nor\n0 * group(cluster_infrastructure_provider)\n"}}]}]},{"edges":[{"from":"4.19.1","to":"4.19.5"},{"from":"4.19.3","to":"4.19.4"},{"from":"4.19.3","to":"4.19.5"},{"from":"4.19.0","to":"4.19.6"},{"from":"4.19.0","to":"4.19.4"},{"from":"4.19.0","to":"4.19.5"},{"from":"4.19.3","to":"4.19.6"},{"from":"4.19.2","to":"4.19.5"},{"from":"4.19.2","to":"4.19.4"},{"from":"4.19.1","to":"4.19.4"},{"from":"4.19.1","to":"4.19.6"},{"from":"4.19.2","to":"4.19.6"}],"risks":[{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.18","to":"4.19.2"},{"from":"4.18.19","to":"4.19.2"},{"from":"4.18.16","to":"4.19.0"},{"from":"4.18.16","to":"4.19.1"},{"from":"4.18.17","to":"4.19.1"},{"from":"4.18.16","to":"4.19.2"},{"from":"4.18.17","to":"4.19.0"},{"from":"4.18.17","to":"4.19.2"},{"from":"4.18.18","to":"4.19.1"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1109","name":"HCPMetallbCNOCannotDeployFRRK8S","message":"On Hosted Control Plane (HCP/HyperShift) clusters with installed MetalLB operator, Cluster Network Operator fails to\ndeploy a critical component FRR-k8s when updated. MetalLB will stop working properly and stop advertising services,\nmaking them potentially unreachable from outside the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\ngroup by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\nand on (_id) (\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n)\nor on (_id) (\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1110","name":"HCPServiceHealthCheckDisruption","message":"When Hosted Control Plane (HCP/HyperShift) clusters running on AWS update a node pool, the Services of type\nLoadBalancer may experience temporary availability disruption because health checks are not set up properly to monitor\nNode readiness state.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\n  or\n  0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n)\n* on (_id) group_left (type) (\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3357","name":"OldBootImagesComposeFSvsGrubProbe","message":"Upgrade to 4.19 will fail due to a boot image incompatibility issue if a cluster was born in 4.2 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  label_replace(group by (version) (cluster_version{_id=\"\",type=\"initial\",version=~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"yes, so possibly actually born in 4.2 or earlier\", \"\", \"\")\n  or\n  label_replace(0 * group by (version) (cluster_version{_id=\"\",type=\"initial\",version!~\"4[.][0-9][.].*\"}),\"born_by_4_9\", \"no, born in 4.10 or later\", \"\", \"\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/STOR-2486","name":"VSphereStorageMountIssues","message":"vSphere customers using vSAN file volumes can't mount vSphere shared volumes and NFS volumes which server do not set NFS4ERR_ATTRNOTSUPP","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_infrastructure_provider{type=~\"VSphere|None\"})\nor\n0 * group(cluster_infrastructure_provider)\n"}}]}]},{"edges":[{"from":"4.18.22","to":"4.19.10"},{"from":"4.18.23","to":"4.19.11"},{"from":"4.18.22","to":"4.19.11"},{"from":"4.18.23","to":"4.19.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]}]},{"edges":[{"from":"4.18.20","to":"4.19.9"},{"from":"4.18.21","to":"4.19.9"},{"from":"4.18.19","to":"4.19.9"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.5","to":"4.19.7"},{"from":"4.19.4","to":"4.19.7"},{"from":"4.19.6","to":"4.19.7"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.22","to":"4.19.16"},{"from":"4.18.24","to":"4.19.16"},{"from":"4.18.25","to":"4.19.16"},{"from":"4.18.23","to":"4.19.17"},{"from":"4.18.20","to":"4.19.17"},{"from":"4.18.21","to":"4.19.17"},{"from":"4.18.26","to":"4.19.16"},{"from":"4.18.22","to":"4.19.17"},{"from":"4.18.20","to":"4.19.16"},{"from":"4.18.25","to":"4.19.17"},{"from":"4.18.23","to":"4.19.16"},{"from":"4.18.19","to":"4.19.17"},{"from":"4.18.24","to":"4.19.17"},{"from":"4.18.26","to":"4.19.17"},{"from":"4.18.19","to":"4.19.16"},{"from":"4.18.21","to":"4.19.16"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]}]},{"edges":[{"from":"4.18.1","to":"4.18.11"},{"from":"4.18.4","to":"4.18.11"},{"from":"4.18.2","to":"4.18.11"},{"from":"4.18.3","to":"4.18.11"},{"from":"4.18.1","to":"4.18.10"},{"from":"4.18.4","to":"4.18.10"},{"from":"4.18.2","to":"4.18.10"},{"from":"4.18.3","to":"4.18.10"},{"from":"4.18.5","to":"4.18.11"},{"from":"4.18.5","to":"4.18.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CNF-17689","name":"MetallbBgpBfdFrrRpm","message":"Clusters using MetalLB BFD capabilities alongside BGP can fail to establish BGP peering, reducing the availability of LoadBalancer services exposed by MetalLB, or even making them unreachable","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.0-rc.2","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.1","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.3","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.2","to":"4.19.0-ec.1"},{"from":"4.18.0-rc.3","to":"4.19.0-ec.1"},{"from":"4.18.0-rc.0","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.0","to":"4.19.0-ec.1"},{"from":"4.18.0-rc.1","to":"4.19.0-ec.1"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/STOR-2486","name":"VSphereStorageMountIssues","message":"vSphere customers using vSAN file volumes can't mount vSphere shared volumes and NFS volumes which server do not set NFS4ERR_ATTRNOTSUPP","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_infrastructure_provider{type=~\"VSphere|None\"})\nor\n0 * group(cluster_infrastructure_provider)\n"}}]}]},{"edges":[{"from":"4.18.21","to":"4.19.13"},{"from":"4.18.19","to":"4.19.12"},{"from":"4.18.20","to":"4.19.13"},{"from":"4.18.20","to":"4.19.12"},{"from":"4.18.21","to":"4.19.12"},{"from":"4.18.19","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.19.10","to":"4.19.15"},{"from":"4.19.1","to":"4.19.15"},{"from":"4.19.6","to":"4.19.15"},{"from":"4.19.5","to":"4.19.15"},{"from":"4.19.11","to":"4.19.15"},{"from":"4.19.1","to":"4.19.14"},{"from":"4.19.7","to":"4.19.15"},{"from":"4.19.2","to":"4.19.15"},{"from":"4.19.8","to":"4.19.14"},{"from":"4.19.0","to":"4.19.15"},{"from":"4.19.4","to":"4.19.15"},{"from":"4.19.8","to":"4.19.15"},{"from":"4.19.10","to":"4.19.14"},{"from":"4.19.13","to":"4.19.14"},{"from":"4.19.7","to":"4.19.14"},{"from":"4.19.9","to":"4.19.15"},{"from":"4.19.9","to":"4.19.14"},{"from":"4.19.3","to":"4.19.14"},{"from":"4.19.12","to":"4.19.15"},{"from":"4.19.6","to":"4.19.14"},{"from":"4.19.14","to":"4.19.15"},{"from":"4.19.3","to":"4.19.15"},{"from":"4.19.13","to":"4.19.15"},{"from":"4.19.2","to":"4.19.14"},{"from":"4.19.12","to":"4.19.14"},{"from":"4.19.0","to":"4.19.14"},{"from":"4.19.4","to":"4.19.14"},{"from":"4.19.5","to":"4.19.14"},{"from":"4.19.11","to":"4.19.14"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.3","to":"4.18.4"},{"from":"4.18.3","to":"4.18.5"},{"from":"4.18.0-rc.5","to":"4.18.1"},{"from":"4.18.0-rc.9","to":"4.18.1"},{"from":"4.18.1","to":"4.18.3"},{"from":"4.18.0-rc.6","to":"4.18.1"},{"from":"4.18.1","to":"4.18.5"},{"from":"4.18.0-rc.7","to":"4.18.1"},{"from":"4.18.0-rc.8","to":"4.18.1"},{"from":"4.18.2","to":"4.18.3"},{"from":"4.18.2","to":"4.18.4"},{"from":"4.18.0-rc.4","to":"4.18.1"},{"from":"4.18.4","to":"4.18.5"},{"from":"4.18.1","to":"4.18.2"},{"from":"4.18.2","to":"4.18.5"},{"from":"4.18.1","to":"4.18.4"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.7","to":"4.18.15"},{"from":"4.18.9","to":"4.18.13"},{"from":"4.18.9","to":"4.18.12"},{"from":"4.18.3","to":"4.18.17"},{"from":"4.18.7","to":"4.18.14"},{"from":"4.18.2","to":"4.18.17"},{"from":"4.18.6","to":"4.18.12"},{"from":"4.18.10","to":"4.18.12"},{"from":"4.18.11","to":"4.18.16"},{"from":"4.18.8","to":"4.18.12"},{"from":"4.18.8","to":"4.18.17"},{"from":"4.18.10","to":"4.18.17"},{"from":"4.18.8","to":"4.18.15"},{"from":"4.18.11","to":"4.18.17"},{"from":"4.18.10","to":"4.18.16"},{"from":"4.18.9","to":"4.18.14"},{"from":"4.18.4","to":"4.18.17"},{"from":"4.18.11","to":"4.18.15"},{"from":"4.18.10","to":"4.18.14"},{"from":"4.18.10","to":"4.18.15"},{"from":"4.18.9","to":"4.18.15"},{"from":"4.18.11","to":"4.18.12"},{"from":"4.18.6","to":"4.18.17"},{"from":"4.18.7","to":"4.18.16"},{"from":"4.18.7","to":"4.18.17"},{"from":"4.18.8","to":"4.18.16"},{"from":"4.18.8","to":"4.18.14"},{"from":"4.18.6","to":"4.18.15"},{"from":"4.18.6","to":"4.18.16"},{"from":"4.18.6","to":"4.18.14"},{"from":"4.18.8","to":"4.18.13"},{"from":"4.18.1","to":"4.18.17"},{"from":"4.18.9","to":"4.18.16"},{"from":"4.18.11","to":"4.18.14"},{"from":"4.18.10","to":"4.18.13"},{"from":"4.18.7","to":"4.18.12"},{"from":"4.18.6","to":"4.18.13"},{"from":"4.18.5","to":"4.18.17"},{"from":"4.18.11","to":"4.18.13"},{"from":"4.18.7","to":"4.18.13"},{"from":"4.18.9","to":"4.18.17"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4632","name":"ConsoleEnabledTargetDownAlert","message":"The alert TargetDown is triggered if the capability Console is enabled on the cluster.","matchingRules":[{"type":"PromQL","promql":{"promql":"max(cluster_version_capability{name=\"Console\"})"}}]}]},{"edges":[{"from":"4.18.19","to":"4.19.5"},{"from":"4.18.21","to":"4.19.6"},{"from":"4.18.20","to":"4.19.6"},{"from":"4.18.19","to":"4.19.6"},{"from":"4.18.20","to":"4.19.5"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.0-ec.4","to":"4.18.0-rc.1"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.8"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.4"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.3"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.2"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.7"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.10"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.0"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.5"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.9"},{"from":"4.18.0-ec.4","to":"4.18.0-rc.6"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1481","name":"MachineConfigServerCARotation","message":"4.18.0-ec.4 adjusted machine-config server CA management.  The change was reverted in 4.18.0-rc.0, but clusters running 4.18.0-ec.4 need manual steps to be able to scale new Machines.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.5","to":"4.18.9"},{"from":"4.18.2","to":"4.18.9"},{"from":"4.18.4","to":"4.18.8"},{"from":"4.18.5","to":"4.18.8"},{"from":"4.18.1","to":"4.18.9"},{"from":"4.18.2","to":"4.18.8"},{"from":"4.18.1","to":"4.18.8"},{"from":"4.18.4","to":"4.18.7"},{"from":"4.18.3","to":"4.18.8"},{"from":"4.18.3","to":"4.18.7"},{"from":"4.18.1","to":"4.18.7"},{"from":"4.18.3","to":"4.18.9"},{"from":"4.18.4","to":"4.18.9"},{"from":"4.18.2","to":"4.18.7"},{"from":"4.18.5","to":"4.18.7"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.18.21","to":"4.19.7"},{"from":"4.18.20","to":"4.19.7"},{"from":"4.18.19","to":"4.19.7"}],"risks":[{"url":"https://access.redhat.com/solutions/7128495","name":"AROMissingInternalLBSAN","message":"ARO clusters on 4.19 experience issues creating new Machines due to missing the Internal LB SAN in the certificate provisioned by MCO. See https://issues.redhat.com/browse/OCPBUGS-59780","matchingRules":[{"type":"PromQL","promql":{"promql":"group(cluster_operator_conditions{_id=\"\",name=\"aro\"})\nor\n0 * group(cluster_operator_conditions{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.2","to":"4.19.8"},{"from":"4.19.0","to":"4.19.8"},{"from":"4.19.3","to":"4.19.8"},{"from":"4.19.1","to":"4.19.8"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3503","name":"RHEL96Kernel331Panic","message":"After OCP 4.19.8 was tagged Red Hat has become aware of a kernel regression in kernel-5.14.0-570.33.1.el9_6 and as a result 4.19.8 will not ship or be promoted beyond candidate channels. Updates to this version are not recommended. ","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.22","to":"4.19.8"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1834","name":"InvalidArchitectureValueOfMachinesetsAnnotation","message":"Degrade machine-config cluster operator blocks the cluster update if a GCP or AWS cluster has machinesets with \nmultiple labels embedded within their \"capacity.cluster-autoscaler.kubernetes.io/labels\" annotation.\n","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS|GCP\"})\n  or\n  0 * group by (type) (cluster_infrastructure_provider{_id=\"\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/OCPCLOUD-3052","name":"NoCloudConfConfigMap","message":"Upgrade to 4.19 will complete due to an absent cloud-conf ConfigMap in AWS clusters born in 4.13 or earlier.","matchingRules":[{"type":"PromQL","promql":{"promql":"bottomk by (_id) (1,\n  0 * group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\",configmap=\"cloud-conf\"})\n  or\n  group by (_id, namespace, configmap) (kube_configmap_info{_id=\"\",namespace=\"openshift-cloud-controller-manager\"})\n)\n* on (_id) group_left (type)\ntopk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=\"AWS\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!=\"AWS\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3503","name":"RHEL96Kernel331Panic","message":"After OCP 4.19.8 was tagged Red Hat has become aware of a kernel regression in kernel-5.14.0-570.33.1.el9_6 and as a result 4.19.8 will not ship or be promoted beyond candidate channels. Updates to this version are not recommended. ","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.1","to":"4.18.6"},{"from":"4.18.4","to":"4.18.6"},{"from":"4.18.5","to":"4.18.6"},{"from":"4.18.2","to":"4.18.6"},{"from":"4.18.3","to":"4.18.6"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1702","name":"RHELFailedRebootMissingService","message":"RHEL worker nodes will fail to reboot during a node update due to a missing service.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk(1,\n  group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\",label_node_openshift_io_os_id=\"rhel\"})\n  or\n  0 * group by (label_node_openshift_io_os_id) (kube_node_labels{_id=\"\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.0-ec.2","to":"4.19.0-ec.4"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.4"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.6"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.4"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.2"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.10"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.5"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.10"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.2"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.1"},{"from":"4.18.0-rc.8","to":"4.18.0-rc.10"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.1"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.3"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.9"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.0"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.8"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.5"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.3"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.10"},{"from":"4.18.0-rc.8","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.7","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.8"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.1"},{"from":"4.19.0-rc.4","to":"4.19.0-rc.5"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.1"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.8"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.5"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.2"},{"from":"4.19.0-ec.3","to":"4.19.0-ec.4"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.2"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.2"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.3"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.8"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.7"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.8"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.1"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.3"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.7"},{"from":"4.18.0-rc.9","to":"4.18.0-rc.10"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.3"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.2"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.2"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.5"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.0"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.8"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.0"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.7"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.5"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.10"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.2"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.7"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.8"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.9"},{"from":"4.19.0-rc.3","to":"4.19.0-rc.4"},{"from":"4.19.0-ec.4","to":"4.19.0-ec.5"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.3"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.0"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.3"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.7"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.10"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.4"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.8"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.4"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.5"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.5"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.0"},{"from":"4.19.0-ec.3","to":"4.19.0-rc.1"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.7"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.9"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.3"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.1"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.4"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.4"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.0"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.6"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.5"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.2"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.2"},{"from":"4.18.0-rc.4","to":"4.18.0-rc.6"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.7"},{"from":"4.18.0-ec.3","to":"4.18.0-ec.4"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.10"},{"from":"4.19.0-rc.2","to":"4.19.0-rc.3"},{"from":"4.19.0-rc.2","to":"4.19.0-rc.4"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.3"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.5"},{"from":"4.19.0-ec.2","to":"4.19.0-ec.5"},{"from":"4.18.0-rc.5","to":"4.18.0-rc.10"},{"from":"4.19.0-rc.0","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.4"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.1"},{"from":"4.19.0-ec.5","to":"4.19.0-rc.0"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.2"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.1"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.4"},{"from":"4.19.0-ec.1","to":"4.19.0-ec.3"},{"from":"4.19.0-ec.2","to":"4.19.0-rc.4"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.7"},{"from":"4.19.0-rc.1","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.10"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.4"},{"from":"4.19.0-ec.3","to":"4.19.0-ec.5"},{"from":"4.19.0-rc.2","to":"4.19.0-rc.5"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.3"},{"from":"4.18.0-ec.1","to":"4.18.0-ec.2"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.6"},{"from":"4.18.0-rc.6","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.2","to":"4.18.0-rc.5"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.3"},{"from":"4.19.0-ec.1","to":"4.19.0-rc.4"},{"from":"4.19.0-rc.3","to":"4.19.0-rc.5"},{"from":"4.18.0-rc.3","to":"4.18.0-rc.6"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.5"},{"from":"4.19.0-ec.0","to":"4.19.0-rc.2"},{"from":"4.18.0-rc.7","to":"4.18.0-rc.10"},{"from":"4.19.0-ec.4","to":"4.19.0-rc.2"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.4"},{"from":"4.19.0-ec.2","to":"4.19.0-ec.3"},{"from":"4.18.0-ec.3","to":"4.18.0-rc.6"},{"from":"4.18.0-rc.0","to":"4.18.0-rc.9"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.6"},{"from":"4.18.0-rc.1","to":"4.18.0-rc.3"}],"risks":[{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.19.2","to":"4.19.9"},{"from":"4.19.1","to":"4.19.9"},{"from":"4.19.0","to":"4.19.9"},{"from":"4.19.1","to":"4.19.10"},{"from":"4.19.1","to":"4.19.11"},{"from":"4.19.2","to":"4.19.11"},{"from":"4.19.3","to":"4.19.10"},{"from":"4.19.0","to":"4.19.10"},{"from":"4.19.3","to":"4.19.11"},{"from":"4.19.3","to":"4.19.9"},{"from":"4.19.2","to":"4.19.10"},{"from":"4.19.0","to":"4.19.11"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.3","to":"4.19.7"},{"from":"4.19.2","to":"4.19.7"},{"from":"4.19.1","to":"4.19.7"},{"from":"4.19.0","to":"4.19.7"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.22","to":"4.19.12"},{"from":"4.18.24","to":"4.19.13"},{"from":"4.18.24","to":"4.19.12"},{"from":"4.18.22","to":"4.19.13"},{"from":"4.18.23","to":"4.19.12"},{"from":"4.18.23","to":"4.19.13"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.9","to":"4.18.11"},{"from":"4.18.6","to":"4.18.10"},{"from":"4.18.8","to":"4.18.10"},{"from":"4.18.7","to":"4.18.10"},{"from":"4.18.7","to":"4.18.11"},{"from":"4.18.6","to":"4.18.11"},{"from":"4.18.10","to":"4.18.11"},{"from":"4.18.9","to":"4.18.10"},{"from":"4.18.8","to":"4.18.11"}],"risks":[{"url":"https://issues.redhat.com/browse/CNF-17689","name":"MetallbBgpBfdFrrRpm","message":"Clusters using MetalLB BFD capabilities alongside BGP can fail to establish BGP peering, reducing the availability of LoadBalancer services exposed by MetalLB, or even making them unreachable","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (_id, name) (csv_succeeded{_id=\"\", name=~\"metallb-operator[.].*\"})\n  or on (_id)\n  0 * label_replace(group by (_id) (csv_succeeded{_id=\"\"}), \"name\", \"metallb operator not installed\", \"name\", \".*\")\n)\n"}}]}]},{"edges":[{"from":"4.18.0-rc.1","to":"4.18.1"},{"from":"4.18.0-rc.10","to":"4.18.1"},{"from":"4.18.0-rc.2","to":"4.18.1"},{"from":"4.18.0-rc.3","to":"4.18.1"},{"from":"4.18.0-ec.3","to":"4.18.1"},{"from":"4.18.0-rc.0","to":"4.18.1"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPNODE-3074","name":"CRIOLayerCompressionPulls","message":"The CRI-O container runtime may fail to pull images with certain layer compression characteristics","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.19.0-ec.0","to":"4.19.0-ec.3"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.2"},{"from":"4.19.0-ec.0","to":"4.19.0-ec.1"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1585","name":"LabeledMachineConfigAndContainerRuntimeConfigBlocksMCO","message":"Some clusters with some KubeletConfigs or ContainerRuntimeConfigs will have issues updating MachineConfigPools.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.19.7","to":"4.19.11"},{"from":"4.19.7","to":"4.19.9"},{"from":"4.19.7","to":"4.19.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]},{"edges":[{"from":"4.19.6","to":"4.19.8"},{"from":"4.19.4","to":"4.19.8"},{"from":"4.19.5","to":"4.19.8"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/COS-3503","name":"RHEL96Kernel331Panic","message":"After OCP 4.19.8 was tagged Red Hat has become aware of a kernel regression in kernel-5.14.0-570.33.1.el9_6 and as a result 4.19.8 will not ship or be promoted beyond candidate channels. Updates to this version are not recommended. ","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.22","to":"4.18.23"}],"risks":[{"url":"https://issues.redhat.com/browse/RUN-3446","name":"CrunConflictsWithNVIDIA","message":"Some crun 1.23 releases conflict with the NVIDIA GPU Operator over eBPF, causing issues with GPU workloads.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (name) (csv_succeeded{_id=\"\", name=~\"gpu-operator-certified[.].*\"})\nor on (_id)\n0 * group(csv_count{_id=\"\"})"}}]}]},{"edges":[{"from":"4.19.7","to":"4.19.13"},{"from":"4.19.7","to":"4.19.12"}],"risks":[{"url":"https://issues.redhat.com/browse/MCO-1890","name":"MachineConfigNodesV1AlphaControlPlaneLabels","message":"Standalone clusters born in 4.11 or earlier whose control-plane nodes lack the control-plane role may need that role added to update to the target release.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (role) (kube_node_role{_id=\"\",role=\"control-plane\"})\nor on ()\n1 * group by (role) (kube_node_role{_id=\"\",role=\"master\"})\nor on ()\n0 * topk(1, count by (role) (kube_node_role{_id=\"\"}))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]},{"url":"https://issues.redhat.com/browse/MCO-1896","name":"OSUpdateFailureDueToImagePullPolicy","message":"Clusters with restrictive image policies may struggle with OS updates when the OS image is already on the local disk. Please update to 4.19.16 or later where this issue is resolved.","matchingRules":[{"type":"PromQL","promql":{"promql":"0 * group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\ngroup by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]}]},{"edges":[{"from":"4.18.0-ec.2","to":"4.18.0-rc.1"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.3"},{"from":"4.18.0-ec.2","to":"4.18.0-ec.3"},{"from":"4.18.0-ec.1","to":"4.18.0-ec.3"},{"from":"4.18.0-ec.0","to":"4.18.0-rc.0"},{"from":"4.18.0-ec.2","to":"4.18.0-ec.4"},{"from":"4.18.0-ec.0","to":"4.18.0-ec.4"},{"from":"4.18.0-ec.0","to":"4.18.0-rc.1"},{"from":"4.18.0-ec.2","to":"4.18.0-rc.0"},{"from":"4.18.0-ec.1","to":"4.18.0-ec.4"},{"from":"4.18.0-ec.1","to":"4.18.0-rc.1"},{"from":"4.18.0-ec.1","to":"4.18.0-rc.0"}],"risks":[{"url":"https://issues.redhat.com/browse/OCPBUGS-42671","name":"CMOSuddenStrictConfigValidation","message":"The Cluster Monitoring Operator (CMO) now validates the content of its ConfigMaps more strictly.\n\nThis may result in the operator being marked as `Degraded` and `Unavailable` while updating to a version with strict validation if any of the ConfigMaps contain invalid configurations.\n\nThe error messages should be clear enough to help identify and correct any eventual issues.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/OTA-1599","name":"PreRelease","message":"This is a pre-release version, and you should update to a release version instead. If it is a minor update, it is suggested to upgrade to the latest patch version first.","matchingRules":[{"type":"Always"}]}]},{"edges":[{"from":"4.18.20","to":"4.19.11"},{"from":"4.18.21","to":"4.19.11"},{"from":"4.18.20","to":"4.19.10"},{"from":"4.18.21","to":"4.19.10"},{"from":"4.18.19","to":"4.19.11"},{"from":"4.18.19","to":"4.19.10"}],"risks":[{"url":"https://issues.redhat.com/browse/CONSOLE-4762","name":"ConsoleCrashOnMissingPlugin","message":"If a Console Operator configuration resource references a plugin name for which there is no corresponding ConsolePlugin resource, the Console may crashloop after the cluster is updated to an affected version.","matchingRules":[{"type":"Always"}]},{"url":"https://issues.redhat.com/browse/CNTRLPLANE-1407","name":"HyperShiftProxyScheme","message":"Hosted/HyperShift clusters where HostedCluster has a configured proxy needed for IDP or ingress canary probes may lose the ability to login.","matchingRules":[{"type":"PromQL","promql":{"promql":"group by (_id, invoker) (cluster_installer{_id=\"\",invoker=\"hypershift\"})\nor\n0 * group by (_id, invoker) (cluster_installer{_id=\"\"})\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6196","name":"IPsecLargeClusterConnectivity","message":"Large clusters with enabled IPsec might experience intermittent loss of pod-to-pod connectivity. This prevents some pods on certain nodes from reaching services on other nodes, resulting in connection timeouts.","matchingRules":[{"type":"PromQL","promql":{"promql":"(\n  group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"enabled\", \"\", \"\") == 1)\n  or on (_id)\n  0 * group by (ipsec) (label_replace(max_over_time(ovnkube_controller_ipsec_enabled{_id=\"\"}[1h]), \"ipsec\", \"disabled\", \"\", \"\") == 0)\n) and on (_id) (\n  group by (resource) (max_over_time(apiserver_storage_objects{_id=\"\",resource=\"nodes\"}[1h]) > 120)\n)\nor on (_id)\n0 * group(max_over_time(apiserver_storage_objects{_id=\"\"}[1h]))\n"}}]},{"url":"https://issues.redhat.com/browse/CORENET-6419","name":"NMStateServiceFailure","message":"The NMState service can fail on baremetal cluster nodes, causing node scaleups and re-deployment failures.","matchingRules":[{"type":"PromQL","promql":{"promql":"topk by (_id) (1,\n  group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type=~\"None|BareMetal\"})\n  or\n  0 * group by (_id, type) (cluster_infrastructure_provider{_id=\"\",type!~\"None|BareMetal\"})\n)\n"}}]}]}]}